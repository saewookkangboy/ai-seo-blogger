# app/services/content_generator.py

import openai
from typing import Optional, Dict, List, Any, Tuple
from ..config import settings
from ..exceptions import ContentGenerationError, APIKeyError
from ..utils.logger import setup_logger
from .keyword_manager import keyword_manager
import os
import json
import threading
from datetime import datetime
import re
import asyncio
import time

logger = setup_logger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
client = None

# API ì‚¬ìš©ëŸ‰ íŒŒì¼ ê²½ë¡œ
API_USAGE_FILE_PATH = os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(__file__)), '..', 'api_usage.json'))
API_USAGE_LOCK = threading.Lock()

# ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì„¤ì • (ìµœì í™”)
OPENAI_TIMEOUT = 30  # 30ì´ˆë¡œ ë‹¨ì¶• (ì†ë„ í–¥ìƒ)
MAX_RETRIES = 2  # ì¬ì‹œë„ íšŸìˆ˜ ë‹¨ì¶• (ì†ë„ í–¥ìƒ)
CACHE_DURATION = 1800  # ìºì‹œ ì‹œê°„ 30ë¶„ìœ¼ë¡œ ë‹¨ì¶• (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
MAX_CONCURRENT_GENERATIONS = 2  # ë™ì‹œ ìƒì„± ìˆ˜ ì œí•œ (ì•ˆì •ì„±)
GENERATION_DELAY = 0.1  # ìƒì„± ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)

# ë©”ëª¨ë¦¬ ìºì‹œ (ê°„ë‹¨í•œ êµ¬í˜„)
content_cache: Dict[str, Tuple[Dict[str, Any], float]] = {}
cache_lock = threading.Lock()

def _initialize_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global client
    
    api_key = settings.get_openai_api_key()
    if not api_key:
        logger.warning("ìœ íš¨í•œ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return False
    
    try:
        client = openai.AsyncOpenAI(
            api_key=api_key,
            timeout=openai.Timeout(OPENAI_TIMEOUT)  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        )
        logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
    except Exception as e:
        logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def _get_cache_key(text: str, keywords: str, content_length: str, ai_mode: str) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    import hashlib
    content = f"{text[:100]}{keywords}{content_length}{ai_mode}"
    return hashlib.md5(content.encode()).hexdigest()

def _get_cached_content(cache_key: str) -> Optional[Dict[str, Any]]:
    """ìºì‹œëœ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°"""
    with cache_lock:
        if cache_key in content_cache:
            cached_data, timestamp = content_cache[cache_key]
            if time.time() - timestamp < CACHE_DURATION:
                logger.info("ìºì‹œëœ ì½˜í…ì¸  ì‚¬ìš©")
                return cached_data
            else:
                del content_cache[cache_key]
    return None

def _set_cached_content(cache_key: str, content: Dict[str, Any]):
    """ì½˜í…ì¸ ë¥¼ ìºì‹œì— ì €ì¥"""
    with cache_lock:
        content_cache[cache_key] = (content, time.time())
        # ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        if len(content_cache) > 50:
            oldest_key = min(content_cache.keys(), key=lambda k: content_cache[k][1])
            del content_cache[oldest_key]

def clear_content_cache():
    """ì½˜í…ì¸  ìºì‹œ í´ë¦¬ì–´"""
    global content_cache
    with cache_lock:
        content_cache.clear()
        logger.info("ì½˜í…ì¸  ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤.")

def clear_specific_cache(text: str, keywords: str, content_length: str, ai_mode: str):
    """íŠ¹ì • ì½˜í…ì¸ ì˜ ìºì‹œ í´ë¦¬ì–´"""
    cache_key = _get_cache_key(text, keywords, content_length, ai_mode)
    with cache_lock:
        if cache_key in content_cache:
            del content_cache[cache_key]
            logger.info(f"íŠ¹ì • ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤: {cache_key}")

# ë™ì‹œ ìƒì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
generation_semaphore = asyncio.Semaphore(MAX_CONCURRENT_GENERATIONS)

def is_gemini_quota_exceeded(error_message: str) -> bool:
    """Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ì¸ì§€ í™•ì¸"""
    quota_error_patterns = [
        "quota exceeded",
        "quota limit",
        "rate limit exceeded",
        "resource exhausted",
        "quota has been exceeded",
        "quota limit exceeded",
        "429",
        "too many requests"
    ]
    error_lower = error_message.lower()
    return any(pattern in error_lower for pattern in quota_error_patterns)

async def translate_with_openai(text: str, target_lang: str = "ko") -> str:
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•œ fallback ë²ˆì—­ í•¨ìˆ˜
    """
    global client
    
    if not text or not text.strip():
        return ""
    
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    if not client and not _initialize_client():
        logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return text
    
    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[
                {
                    "role": "system",
                    "content": f"ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ {target_lang}ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": text
                }
            ],
            max_tokens=settings.openai_max_tokens,
            temperature=0.3
        )
        
        translated_text = response.choices[0].message.content.strip()
        logger.info(f"OpenAI ë²ˆì—­ ì™„ë£Œ: {len(text)}ì â†’ {len(translated_text)}ì")
        return translated_text
        
    except Exception as e:
        logger.error(f"OpenAI ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")
        return text

async def create_blog_post(text: str, keywords: str, rule_guidelines: Optional[list] = None, content_length: str = "3000", ai_mode: Optional[str] = None) -> Dict:
    """
    ë²ˆì—­ëœ í…ìŠ¤íŠ¸ì™€ í‚¤ì›Œë“œ, ì¶”ê°€ ê°€ì´ë“œë¼ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ ìƒì„±í•©ë‹ˆë‹¤. (ì„±ëŠ¥ ìµœì í™”)
    AI SEO ìµœì í™”ë¥¼ ìœ„í•œ êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    Gemini 2.0 Flashì™€ OpenAIë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
    """
    # ë™ì‹œ ìƒì„± ì œì–´
    async with generation_semaphore:
        global client
        
        start_time = time.time()
        
        # ì…ë ¥ ê²€ì¦
        if not text or not text.strip():
            logger.warning("ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return _generate_default_template("", keywords, rule_guidelines, content_length, ai_mode)
        
        # ìºì‹œ í™•ì¸
        cache_key = _get_cache_key(text, keywords, content_length, ai_mode or "")
        cached_content = _get_cached_content(cache_key)
        if cached_content:
            logger.info("ìºì‹œëœ ì½˜í…ì¸  ìƒì„± ê²°ê³¼ ì‚¬ìš©")
            return cached_content
        
        # ìƒì„± ìš”ì²­ ê°„ ì§€ì—° (API ë¶€í•˜ ë°©ì§€)
        await asyncio.sleep(GENERATION_DELAY)
    
    # Gemini 2.0 Flash ëª¨ë“œì¸ ê²½ìš° Gemini ì‚¬ìš©
    if ai_mode == "gemini_2_0_flash":
        try:
            result = await _create_blog_post_with_gemini(text, keywords, rule_guidelines, content_length, ai_mode)
            if result:
                _set_cached_content(cache_key, result)
                return result
        except Exception as e:
            error_message = str(e)
            if is_gemini_quota_exceeded(error_message):
                logger.warning("Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ OpenAIë¡œ fallbackí•©ë‹ˆë‹¤.")
            else:
                logger.warning(f"Gemini 2.0 Flash ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨, OpenAIë¡œ fallback: {e}")
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    if not client and not _initialize_client():
        logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. ê¸°ë³¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return _generate_default_template(text, keywords, rule_guidelines, content_length, ai_mode)
    
    try:
        # ì½˜í…ì¸  ê¸¸ì´ ì„¤ì •
        target_length = int(content_length) if content_length.isdigit() else 3000
        
        # AI ëª¨ë“œì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        if ai_mode == "creative":
            style_instruction = "ì°½ì˜ì ì´ê³  í¥ë¯¸ë¡œìš´ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ì„¸ìš”."
        elif ai_mode == "informative":
            style_instruction = "ì •ë³´ê°€ í’ë¶€í•˜ê³  êµìœ¡ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        elif ai_mode == "professional":
            style_instruction = "ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        else:
            style_instruction = "ê· í˜• ì¡íŒ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        
        # ê·œì¹™ ê°€ì´ë“œë¼ì¸ ì²˜ë¦¬
        rules_text = ""
        if rule_guidelines:
            rules_text = "\n".join([f"- {rule}" for rule in rule_guidelines])
        
        # ì½˜í…ì¸  ìŠ¤íƒ€ì¼ë³„ ê°€ì´ë“œë¼ì¸ ì¶”ê°€
        style_guidelines = ""
        if ai_mode:
            if ai_mode == "ë‰´ìŠ¤":
                style_guidelines = """
ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ê°ê´€ì ì´ê³  ì‚¬ì‹¤ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±
- 5W1H (ëˆ„ê°€, ì–¸ì œ, ì–´ë””ì„œ, ë¬´ì—‡ì„, ì™œ, ì–´ë–»ê²Œ) í¬í•¨
- ìµœì‹ ì„±ê³¼ ì‹œì˜ì„± ê°•ì¡°
- ìš”ì•½: í•µì‹¬ ì‚¬ì‹¤ë§Œ ê°„ê²°í•˜ê²Œ (300ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì‹œê°„ìˆœ ë˜ëŠ” ì¤‘ìš”ë„ìˆœìœ¼ë¡œ êµ¬ì„±
- ê°œì¸ì  ì˜ê²¬ ë°°ì œ, ê°ê´€ì  ì„œìˆ 
"""
            elif ai_mode == "ë¦¬ë·°":
                style_guidelines = """
ë¦¬ë·° ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ì¥ë‹¨ì ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„œìˆ 
- ê°œì¸ì  ê²½í—˜ê³¼ ì²´í—˜ ì¤‘ì‹¬
- êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±° ì œì‹œ
- ìš”ì•½: í•µì‹¬ í‰ê°€ì™€ ì¶”ì²œ ì—¬ë¶€ (400ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì¥ì , ë‹¨ì , ê²°ë¡  ìˆœìœ¼ë¡œ êµ¬ì„±
- ì†”ì§í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤ ìœ ì§€
"""
            elif ai_mode == "ê°€ì´ë“œ":
                style_guidelines = """
ê°€ì´ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…
- ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì •ë³´ ì œê³µ
- ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸íˆ ì„¤ëª…
- ìš”ì•½: í•µì‹¬ ë‹¨ê³„ì™€ ëª©í‘œ (350ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ë‹¨ê³„ë³„ ìˆœì„œëŒ€ë¡œ êµ¬ì„±
- ì²´í¬ë¦¬ìŠ¤íŠ¸ë‚˜ íŒ í¬í•¨
"""
            elif ai_mode == "ìš”ì•½":
                style_guidelines = """
ìš”ì•½ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬
- ë¶ˆí•„ìš”í•œ ì„¤ëª… ì œê±°
- ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥
- ìš”ì•½: í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ê²°í•˜ê²Œ (250ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì¤‘ìš”ë„ìˆœìœ¼ë¡œ í•µì‹¬ë§Œ ë‚˜ì—´
- ë¹ ë¥¸ ì •ë³´ ì „ë‹¬ì— ìµœì í™”
"""
            elif ai_mode == "ë¸”ë¡œê·¸":
                style_guidelines = """
ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ê°œì¸ì  ì¸ì‚¬ì´íŠ¸ì™€ ê²½í—˜ ì¤‘ì‹¬
- ë…ìì™€ì˜ ì†Œí†µí•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±
- ì‹¤ìš©ì  ì¡°ì–¸ê³¼ ê°œì¸ì  ê²¬í•´ í¬í•¨
- ìš”ì•½: ê°œì¸ì  ê´€ì ê³¼ í•µì‹¬ ë©”ì‹œì§€ (400ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ê²½í—˜ë‹´, ì¸ì‚¬ì´íŠ¸, ì¡°ì–¸ ìˆœìœ¼ë¡œ êµ¬ì„±
- ì¹œê·¼í•˜ê³  ì†”ì§í•œ ì–´ì¡° ìœ ì§€
"""
            elif ai_mode == "enhanced":
                style_guidelines = """
í–¥ìƒëœ ëª¨ë“œ ê°€ì´ë“œë¼ì¸:
- AI ë¶„ì„ê³¼ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ í¬í•¨
- ì‹¬ì¸µì  ë¶„ì„ê³¼ ì „ë¬¸ì  ê´€ì 
- ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì¢…í•©ì  ë¶„ì„
- ìš”ì•½: AI ë¶„ì„ ê²°ê³¼ì™€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (500ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ë¶„ì„, ì¸ì‚¬ì´íŠ¸, ì „ë§ ìˆœìœ¼ë¡œ êµ¬ì„±
- ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
"""
        
        # ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ê°€ì´ë“œë¼ì¸
        summary_guidelines = """
ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ê°€ì´ë“œë¼ì¸:
- ìš”ì•½: ì™„ë²½í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±, 500ì ì´ë‚´
- ì£¼ìš” ë‚´ìš©: í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ë¶„
- í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- ë…ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°
- ê° ì„¹ì…˜ë³„ë¡œ ëª…í™•í•œ ì œëª© ì‚¬ìš©
"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEO ìµœì í™”ëœ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
{text}

ì£¼ìš” í‚¤ì›Œë“œ: {keywords}

ìš”êµ¬ì‚¬í•­:
- ëª©í‘œ ê¸¸ì´: ì•½ {target_length}ì
- ìŠ¤íƒ€ì¼: {style_instruction}
- SEO ìµœì í™”: í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- êµ¬ì¡°: ì œëª©, ì†Œì œëª©, ë³¸ë¬¸, ê²°ë¡  í¬í•¨
- HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶”ê°€ ê·œì¹™:
{rules_text}

{style_guidelines}

{summary_guidelines}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
```html
<h1>ì œëª©</h1>
<meta name="description" content="ë©”íƒ€ ì„¤ëª…">
<p>ë³¸ë¬¸ ë‚´ìš©...</p>
```

ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª…ë„ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.
"""

        # API í˜¸ì¶œ
        for attempt in range(MAX_RETRIES):
            try:
                response = await client.chat.completions.create(
                    model=settings.openai_model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì´ì ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤. ê³ í’ˆì§ˆì˜ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=settings.openai_max_tokens,
                    temperature=0.7
                )
                
                generated_content = response.choices[0].message.content.strip()
                
                # HTML íƒœê·¸ ì¶”ì¶œ
                title_match = re.search(r'<h1[^>]*>(.*?)</h1>', generated_content, re.IGNORECASE | re.DOTALL)
                meta_match = re.search(r'<meta[^>]*name="description"[^>]*content="([^"]*)"', generated_content, re.IGNORECASE)
                
                title = title_match.group(1).strip() if title_match else f"{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}"
                meta_description = meta_match.group(1).strip() if meta_match else f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                
                # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                clean_content = re.sub(r'<[^>]+>', '', generated_content)
                word_count = len(clean_content.split())
                
                result = {
                    'post': generated_content,
                    'title': title,
                    'meta_description': meta_description,
                    'keywords': keywords,
                    'word_count': word_count,
                    'content_length': content_length,
                    'ai_mode': ai_mode or 'openai'
                }
                
                generation_time = time.time() - start_time
                logger.info(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ (ìƒì„±ëœ ì½˜í…ì¸  ê¸¸ì´: {len(generated_content)}ì, ì†Œìš”ì‹œê°„: {generation_time:.2f}ì´ˆ)")
                
                _set_cached_content(cache_key, result)
                return result
                
            except Exception as e:
                logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt < MAX_RETRIES - 1:
                    await asyncio.sleep(1 * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                else:
                    raise ContentGenerationError(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return _generate_default_template(text, keywords, rule_guidelines, content_length, ai_mode)

async def _create_blog_post_with_gemini(text: str, keywords: str, rule_guidelines: Optional[list] = None, content_length: str = "5000", ai_mode: Optional[str] = None) -> Dict:
    """
    Gemini 2.0 Flash APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        import httpx
        
        # Gemini API í‚¤ í™•ì¸
        from .translator import get_gemini_api_key
        api_key = get_gemini_api_key()
        if not api_key:
            raise ContentGenerationError("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì½˜í…ì¸  ê¸¸ì´ ì„¤ì •
        target_length = int(content_length) if content_length.isdigit() else 5000
        
        # ê·œì¹™ ê°€ì´ë“œë¼ì¸ ì²˜ë¦¬
        rules_text = ""
        if rule_guidelines:
            rules_text = "\n".join([f"- {rule}" for rule in rule_guidelines])
        
        # ì½˜í…ì¸  ìŠ¤íƒ€ì¼ë³„ ê°€ì´ë“œë¼ì¸ ì¶”ê°€
        style_guidelines = ""
        if ai_mode:
            if ai_mode == "ë‰´ìŠ¤":
                style_guidelines = """
ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ê°ê´€ì ì´ê³  ì‚¬ì‹¤ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±
- 5W1H (ëˆ„ê°€, ì–¸ì œ, ì–´ë””ì„œ, ë¬´ì—‡ì„, ì™œ, ì–´ë–»ê²Œ) í¬í•¨
- ìµœì‹ ì„±ê³¼ ì‹œì˜ì„± ê°•ì¡°
- ìš”ì•½: í•µì‹¬ ì‚¬ì‹¤ë§Œ ê°„ê²°í•˜ê²Œ (300ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì‹œê°„ìˆœ ë˜ëŠ” ì¤‘ìš”ë„ìˆœìœ¼ë¡œ êµ¬ì„±
- ê°œì¸ì  ì˜ê²¬ ë°°ì œ, ê°ê´€ì  ì„œìˆ 
"""
            elif ai_mode == "ë¦¬ë·°":
                style_guidelines = """
ë¦¬ë·° ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ì¥ë‹¨ì ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„œìˆ 
- ê°œì¸ì  ê²½í—˜ê³¼ ì²´í—˜ ì¤‘ì‹¬
- êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±° ì œì‹œ
- ìš”ì•½: í•µì‹¬ í‰ê°€ì™€ ì¶”ì²œ ì—¬ë¶€ (400ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì¥ì , ë‹¨ì , ê²°ë¡  ìˆœìœ¼ë¡œ êµ¬ì„±
- ì†”ì§í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤ ìœ ì§€
"""
            elif ai_mode == "ê°€ì´ë“œ":
                style_guidelines = """
ê°€ì´ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…
- ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì •ë³´ ì œê³µ
- ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸íˆ ì„¤ëª…
- ìš”ì•½: í•µì‹¬ ë‹¨ê³„ì™€ ëª©í‘œ (350ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ë‹¨ê³„ë³„ ìˆœì„œëŒ€ë¡œ êµ¬ì„±
- ì²´í¬ë¦¬ìŠ¤íŠ¸ë‚˜ íŒ í¬í•¨
"""
            elif ai_mode == "ìš”ì•½":
                style_guidelines = """
ìš”ì•½ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬
- ë¶ˆí•„ìš”í•œ ì„¤ëª… ì œê±°
- ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥
- ìš”ì•½: í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ê²°í•˜ê²Œ (250ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì¤‘ìš”ë„ìˆœìœ¼ë¡œ í•µì‹¬ë§Œ ë‚˜ì—´
- ë¹ ë¥¸ ì •ë³´ ì „ë‹¬ì— ìµœì í™”
"""
            elif ai_mode == "ë¸”ë¡œê·¸":
                style_guidelines = """
ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ê°œì¸ì  ì¸ì‚¬ì´íŠ¸ì™€ ê²½í—˜ ì¤‘ì‹¬
- ë…ìì™€ì˜ ì†Œí†µí•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±
- ì‹¤ìš©ì  ì¡°ì–¸ê³¼ ê°œì¸ì  ê²¬í•´ í¬í•¨
- ìš”ì•½: ê°œì¸ì  ê´€ì ê³¼ í•µì‹¬ ë©”ì‹œì§€ (400ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ê²½í—˜ë‹´, ì¸ì‚¬ì´íŠ¸, ì¡°ì–¸ ìˆœìœ¼ë¡œ êµ¬ì„±
- ì¹œê·¼í•˜ê³  ì†”ì§í•œ ì–´ì¡° ìœ ì§€
"""
            elif ai_mode == "enhanced":
                style_guidelines = """
í–¥ìƒëœ ëª¨ë“œ ê°€ì´ë“œë¼ì¸:
- AI ë¶„ì„ê³¼ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ í¬í•¨
- ì‹¬ì¸µì  ë¶„ì„ê³¼ ì „ë¬¸ì  ê´€ì 
- ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì¢…í•©ì  ë¶„ì„
- ìš”ì•½: AI ë¶„ì„ ê²°ê³¼ì™€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (500ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ë¶„ì„, ì¸ì‚¬ì´íŠ¸, ì „ë§ ìˆœìœ¼ë¡œ êµ¬ì„±
- ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
"""
        
        # ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ê°€ì´ë“œë¼ì¸
        summary_guidelines = """
ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ê°€ì´ë“œë¼ì¸:
- ìš”ì•½: ì™„ë²½í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±, 500ì ì´ë‚´
- ì£¼ìš” ë‚´ìš©: í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ë¶„
- í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- ë…ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°
- ê° ì„¹ì…˜ë³„ë¡œ ëª…í™•í•œ ì œëª© ì‚¬ìš©
"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEO ìµœì í™”ëœ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
{text}

ì£¼ìš” í‚¤ì›Œë“œ: {keywords}

ìš”êµ¬ì‚¬í•­:
- ëª©í‘œ ê¸¸ì´: ì•½ {target_length}ì
- SEO ìµœì í™”: í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- êµ¬ì¡°: ì œëª©, ì†Œì œëª©, ë³¸ë¬¸, ê²°ë¡  í¬í•¨
- HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶”ê°€ ê·œì¹™:
{rules_text}

{style_guidelines}

{summary_guidelines}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
```html
<h1>ì œëª©</h1>
<meta name="description" content="ë©”íƒ€ ì„¤ëª…">
<p>ë³¸ë¬¸ ë‚´ìš©...</p>
```

ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª…ë„ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        async with httpx.AsyncClient(timeout=30) as client:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
            payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 8192
                }
            }
            
            response = await client.post(url, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and result['candidates']:
                    generated_content = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    
                    # HTML íƒœê·¸ ì¶”ì¶œ
                    title_match = re.search(r'<h1[^>]*>(.*?)</h1>', generated_content, re.IGNORECASE | re.DOTALL)
                    meta_match = re.search(r'<meta[^>]*name="description"[^>]*content="([^"]*)"', generated_content, re.IGNORECASE)
                    
                    title = title_match.group(1).strip() if title_match else f"{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}"
                    meta_description = meta_match.group(1).strip() if meta_match else f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                    
                    # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    clean_content = re.sub(r'<[^>]+>', '', generated_content)
                    word_count = len(clean_content.split())
                    
                    return {
                        'post': generated_content,
                        'title': title,
                        'meta_description': meta_description,
                        'keywords': keywords,
                        'word_count': word_count,
                        'content_length': content_length,
                        'ai_mode': ai_mode or 'gemini_2_0_flash'
                    }
                else:
                    raise ContentGenerationError("Gemini API ì‘ë‹µì— ìƒì„± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                error_detail = response.text
                logger.error(f"Gemini API ì˜¤ë¥˜: {response.status_code} - {error_detail}")
                raise ContentGenerationError(f"Gemini API ì˜¤ë¥˜: {response.status_code}")
                
    except Exception as e:
        logger.error(f"Gemini ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        raise ContentGenerationError(f"Gemini ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

async def _create_blog_post_with_openai(text: str, keywords: str, rule_guidelines: Optional[list] = None, content_length: str = "3000", ai_mode: Optional[str] = None) -> Dict:
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    global client
    
    if not client and not _initialize_client():
        raise ContentGenerationError("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
    
    try:
        # ì½˜í…ì¸  ê¸¸ì´ ì„¤ì •
        target_length = int(content_length) if content_length.isdigit() else 3000
        
        # AI ëª¨ë“œì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        if ai_mode == "creative":
            style_instruction = "ì°½ì˜ì ì´ê³  í¥ë¯¸ë¡œìš´ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ì„¸ìš”."
        elif ai_mode == "informative":
            style_instruction = "ì •ë³´ê°€ í’ë¶€í•˜ê³  êµìœ¡ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        elif ai_mode == "professional":
            style_instruction = "ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        else:
            style_instruction = "ê· í˜• ì¡íŒ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        
        # ê·œì¹™ ê°€ì´ë“œë¼ì¸ ì²˜ë¦¬
        rules_text = ""
        if rule_guidelines:
            rules_text = "\n".join([f"- {rule}" for rule in rule_guidelines])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEO ìµœì í™”ëœ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
{text}

ì£¼ìš” í‚¤ì›Œë“œ: {keywords}

ìš”êµ¬ì‚¬í•­:
- ëª©í‘œ ê¸¸ì´: ì•½ {target_length}ì
- ìŠ¤íƒ€ì¼: {style_instruction}
- SEO ìµœì í™”: í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- êµ¬ì¡°: ì œëª©, ì†Œì œëª©, ë³¸ë¬¸, ê²°ë¡  í¬í•¨
- HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶”ê°€ ê·œì¹™:
{rules_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
```html
<h1>ì œëª©</h1>
<meta name="description" content="ë©”íƒ€ ì„¤ëª…">
<p>ë³¸ë¬¸ ë‚´ìš©...</p>
```

ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª…ë„ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.
"""

        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì´ì ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤. ê³ í’ˆì§ˆì˜ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=settings.openai_max_tokens,
            temperature=0.7
        )
        
        generated_content = response.choices[0].message.content.strip()
        
        # HTML íƒœê·¸ ì¶”ì¶œ
        title_match = re.search(r'<h1[^>]*>(.*?)</h1>', generated_content, re.IGNORECASE | re.DOTALL)
        meta_match = re.search(r'<meta[^>]*name="description"[^>]*content="([^"]*)"', generated_content, re.IGNORECASE)
        
        title = title_match.group(1).strip() if title_match else f"{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}"
        meta_description = meta_match.group(1).strip() if meta_match else f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        
        # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        clean_content = re.sub(r'<[^>]+>', '', generated_content)
        word_count = len(clean_content.split())
        
        return {
            'post': generated_content,
            'title': title,
            'meta_description': meta_description,
            'keywords': keywords,
            'word_count': word_count,
            'content_length': content_length,
            'ai_mode': ai_mode or 'openai'
        }
        
    except Exception as e:
        logger.error(f"OpenAI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        raise ContentGenerationError(f"OpenAI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def _extract_keywords_from_content(content: str, db_session=None) -> str:
    """
    ì½˜í…ì¸ ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (ê°œì„ ëœ ë²„ì „)
    """
    try:
        # ê¸°ì¡´ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        existing_keywords = set()
        if db_session:
            existing_keywords = keyword_manager.get_existing_keywords(db_session)
        
        # ìƒˆë¡œìš´ í‚¤ì›Œë“œ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ìœ í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        unique_keywords = keyword_manager.extract_unique_keywords(content, existing_keywords)
        
        return unique_keywords
        
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return "AI, ê¸°ìˆ , ë¶„ì„, ê°œë°œ, ì‹œìŠ¤í…œ"

def _generate_default_template(text: str, keywords: str, rule_guidelines: Optional[List[str]] = None, content_length: str = "3000", ai_mode: Optional[str] = None) -> Dict:
    """
    API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # ê¸°ë³¸ ì œëª© ìƒì„±
        title = f"{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}ì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œ"
        
        # ê¸°ë³¸ ë©”íƒ€ ì„¤ëª…
        meta_description = f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        
        # ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±
        content_length_int = int(content_length) if content_length.isdigit() else 3000
        
        # í…ìŠ¤íŠ¸ ìš”ì•½
        summary = text[:200] + "..." if len(text) > 200 else text
        
        # HTML ì½˜í…ì¸  ìƒì„±
        content = f"""
<h1>{title}</h1>
<meta name="description" content="{meta_description}">

<div class="content-intro">
    <p>ì´ ê¸€ì—ì„œëŠ” <strong>{keywords}</strong>ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.</p>
</div>

<div class="content-main">
    <h2>ğŸ“‹ ì£¼ìš” ë‚´ìš©</h2>
    <p>{summary}</p>
    
    <h2>ğŸ” í•µì‹¬ í¬ì¸íŠ¸</h2>
    <ul>
        <li><strong>ì²« ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> {keywords.split(',')[0] if keywords else 'ì£¼ì œ'}ì˜ ê¸°ë³¸ ê°œë…ê³¼ ì¤‘ìš”ì„±</li>
        <li><strong>ë‘ ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> ì‹¤ì œ ì ìš© ë°©ë²•ê³¼ ì‚¬ë¡€</li>
        <li><strong>ì„¸ ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> ì£¼ì˜ì‚¬í•­ê³¼ ëª¨ë²” ì‚¬ë¡€</li>
    </ul>
    
    <h2>ğŸ’¡ ì‹¤ìš©ì ì¸ íŒ</h2>
    <div class="tips-container">
        <div class="tip-item">
            <h3>íŒ 1: íš¨ê³¼ì ì¸ í™œìš©</h3>
            <p>{keywords.split(',')[0] if keywords else 'ì£¼ì œ'}ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”.</p>
        </div>
        <div class="tip-item">
            <h3>íŒ 2: ì£¼ì˜ì‚¬í•­</h3>
            <p>ì¼ë°˜ì ì¸ ì‹¤ìˆ˜ì™€ í”¼í•´ì•¼ í•  í•¨ì •ì— ëŒ€í•´ ì•Œì•„ë³´ì„¸ìš”.</p>
        </div>
    </div>
    
    <h2>ğŸ“Š ìš”ì•½</h2>
    <p>ì´ ê¸€ì„ í†µí•´ {keywords.split(',')[0] if keywords else 'ì£¼ì œ'}ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ , ì‹¤ì œ ìƒí™©ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì§€ì‹ì„ ì–»ì—ˆìŠµë‹ˆë‹¤.</p>
</div>

<style>
.content-intro {{ background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0; }}
.content-main {{ line-height: 1.6; }}
.tips-container {{ display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1rem 0; }}
.tip-item {{ background: #e3f2fd; padding: 1rem; border-radius: 8px; border-left: 4px solid #2196f3; }}
</style>
"""
        
        # ë‹¨ì–´ ìˆ˜ ê³„ì‚°
        text_content = re.sub(r'<[^>]+>', '', content)
        word_count = len(text_content.split())
        
        logger.info("ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
        
        return {
            'post': content,
            'title': title,
            'meta_description': meta_description,
            'keywords': keywords,
            'word_count': word_count,
            'content_length': content_length,
            'ai_mode': ai_mode or 'default_template'
        }
        
    except Exception as e:
        logger.error(f"ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        # ìµœì†Œí•œì˜ ê¸°ë³¸ ì‘ë‹µ
        return {
            'post': f"<h1>{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}</h1><p>ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</p>",
            'title': keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸',
            'meta_description': f"{keywords}ì— ëŒ€í•œ ì •ë³´",
            'keywords': keywords,
            'word_count': 10,
            'content_length': content_length,
            'ai_mode': ai_mode or 'error_fallback'
        }

async def extract_seo_keywords(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ SEO í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        # ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = _extract_default_keywords(text)
        
        # OpenAI APIê°€ ìˆìœ¼ë©´ ë” ì •êµí•œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
        if settings.get_openai_api_key():
            try:
                global client
                if not client and not _initialize_client():
                    return keywords
                
                prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ SEOì— ìœ ìš©í•œ í‚¤ì›Œë“œ 5-7ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
í‚¤ì›Œë“œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text[:1000]}

í‚¤ì›Œë“œ:
"""
                
                response = await client.chat.completions.create(
                    model=settings.openai_model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=200,
                    temperature=0.3
                )
                
                extracted_keywords = response.choices[0].message.content.strip()
                if extracted_keywords and len(extracted_keywords) > 5:
                    return extracted_keywords
                    
            except Exception as e:
                logger.warning(f"OpenAI í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return keywords
        
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return "AI, ê¸°ìˆ , ë¶„ì„, ê°œë°œ, ì‹œìŠ¤í…œ"

def _extract_default_keywords(text: str) -> str:
    """
    ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
    """
    try:
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text)
        
        # í•œêµ­ì–´ ë‹¨ì–´ ì¶”ì¶œ
        korean_words = re.findall(r'[ê°€-í£]+', clean_text)
        
        # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
        word_freq = {}
        for word in korean_words:
            if len(word) >= 2:  # 2ê¸€ì ì´ìƒë§Œ
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 5ê°œ ì¶”ì¶œ
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        keywords = [word for word, freq in sorted_words[:5]]
        
        if keywords:
            return ', '.join(keywords)
        else:
            return "AI, ê¸°ìˆ , ë¶„ì„, ê°œë°œ, ì‹œìŠ¤í…œ"
            
    except Exception as e:
        logger.error(f"ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return "AI, ê¸°ìˆ , ë¶„ì„, ê°œë°œ, ì‹œìŠ¤í…œ"

def increase_api_usage_count(api_name: str):
    """API ì‚¬ìš©ëŸ‰ì„ ê¸°ë¡í•©ë‹ˆë‹¤."""
    try:
        with API_USAGE_LOCK:
            if os.path.exists(API_USAGE_FILE_PATH):
                with open(API_USAGE_FILE_PATH, 'r', encoding='utf-8') as f:
                    usage_data = json.load(f)
            else:
                usage_data = {}
            
            today = datetime.now().strftime('%Y-%m-%d')
            if today not in usage_data:
                usage_data[today] = {}
            
            if api_name not in usage_data[today]:
                usage_data[today][api_name] = 0
            
            usage_data[today][api_name] += 1
            
            with open(API_USAGE_FILE_PATH, 'w', encoding='utf-8') as f:
                json.dump(usage_data, f, ensure_ascii=False, indent=2)
                
    except Exception as e:
        logger.warning(f"API ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì‹¤íŒ¨: {e}")

async def create_enhanced_blog_post(text: str, keywords: str, rule_guidelines: Optional[list] = None, content_length: str = "3000", ai_mode: Optional[str] = None) -> Dict:
    """
    í–¥ìƒëœ ê¸°ëŠ¥ì„ í¬í•¨í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
    - AI ì¶”ì²œ í‚¤ì›Œë“œ (ëª…ì‚¬ ì¤‘ì‹¬, ìµœëŒ€ 10ê°œ)
    - ì£¼ìš” ë‚´ìš©, í•µì‹¬ í¬ì¸íŠ¸, ì‹¤ìš©ì ì¸ íŒ, ìš”ì•½
    - AI ìš”ì•½ (100ì ì´ë‚´)
    - ì‹ ë¢°ë„ í‰ê°€ (5ì  ë§Œì )
    - SEO ìµœì í™” ì ìˆ˜ (10ì  ë§Œì )
    """
    # ë™ì‹œ ìƒì„± ì œì–´
    async with generation_semaphore:
        global client
        
        start_time = time.time()
        
        # ì…ë ¥ ê²€ì¦
        if not text or not text.strip():
            logger.warning("ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return _generate_enhanced_default_template("", keywords, rule_guidelines, content_length, ai_mode)
        
        # ìºì‹œ í™•ì¸
        cache_key = _get_cache_key(text, keywords, content_length, ai_mode or "")
        cached_content = _get_cached_content(cache_key)
        if cached_content:
            logger.info("ìºì‹œëœ ì½˜í…ì¸  ìƒì„± ê²°ê³¼ ì‚¬ìš©")
            return cached_content
        
        # ìƒì„± ìš”ì²­ ê°„ ì§€ì—° (API ë¶€í•˜ ë°©ì§€)
        await asyncio.sleep(GENERATION_DELAY)
    
    # Gemini 2.0 Flash ëª¨ë“œì¸ ê²½ìš° Gemini ì‚¬ìš©
    if ai_mode == "gemini_2_0_flash":
        try:
            result = await _create_enhanced_blog_post_with_gemini(text, keywords, rule_guidelines, content_length, ai_mode)
            if result:
                _set_cached_content(cache_key, result)
                return result
        except Exception as e:
            error_message = str(e)
            if is_gemini_quota_exceeded(error_message):
                logger.warning("Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ OpenAIë¡œ fallbackí•©ë‹ˆë‹¤.")
            else:
                logger.warning(f"Gemini 2.0 Flash ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨, OpenAIë¡œ fallback: {e}")
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    if not client and not _initialize_client():
        logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. ê¸°ë³¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return _generate_enhanced_default_template(text, keywords, rule_guidelines, content_length, ai_mode)
    
    try:
        # ì½˜í…ì¸  ê¸¸ì´ ì„¤ì •
        target_length = int(content_length) if content_length.isdigit() else 3000
        
        # AI ëª¨ë“œì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        if ai_mode == "creative":
            style_instruction = "ì°½ì˜ì ì´ê³  í¥ë¯¸ë¡œìš´ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ì„¸ìš”."
        elif ai_mode == "informative":
            style_instruction = "ì •ë³´ê°€ í’ë¶€í•˜ê³  êµìœ¡ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        elif ai_mode == "professional":
            style_instruction = "ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        else:
            style_instruction = "ê· í˜• ì¡íŒ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        
        # ê·œì¹™ ê°€ì´ë“œë¼ì¸ ì²˜ë¦¬
        rules_text = ""
        if rule_guidelines:
            rules_text = "\n".join([f"- {rule}" for rule in rule_guidelines])
        
        # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEO ìµœì í™”ëœ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
{text}

ì£¼ìš” í‚¤ì›Œë“œ: {keywords}

ìš”êµ¬ì‚¬í•­:
- ëª©í‘œ ê¸¸ì´: ì•½ {target_length}ì
- ìŠ¤íƒ€ì¼: {style_instruction}
- SEO ìµœì í™”: í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- êµ¬ì¡°: ì œëª©, ì†Œì œëª©, ë³¸ë¬¸, ê²°ë¡  í¬í•¨
- HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶”ê°€ ê·œì¹™:
{rules_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

```html
<h1>ì œëª©</h1>
<meta name="description" content="ë©”íƒ€ ì„¤ëª…">

<div class="content-intro">
    <p>ì†Œê°œ ë‚´ìš©...</p>
</div>

<div class="ai-keywords">
    <h2>ğŸ¤– AI ì¶”ì²œ í‚¤ì›Œë“œ</h2>
    <ul>
        <li>í‚¤ì›Œë“œ1</li>
        <li>í‚¤ì›Œë“œ2</li>
        ...
    </ul>
</div>

<div class="main-content">
    <h2>ğŸ“‹ ì£¼ìš” ë‚´ìš©</h2>
    <p>ì£¼ìš” ë‚´ìš©...</p>
    
    <h2>ğŸ” í•µì‹¬ í¬ì¸íŠ¸</h2>
    <ul>
        <li>í•µì‹¬ í¬ì¸íŠ¸ 1</li>
        <li>í•µì‹¬ í¬ì¸íŠ¸ 2</li>
        ...
    </ul>
    
    <h2>ğŸ’¡ ì‹¤ìš©ì ì¸ íŒ</h2>
    <div class="tips-container">
        <div class="tip-item">
            <h3>íŒ 1</h3>
            <p>íŒ ë‚´ìš©...</p>
        </div>
        ...
    </div>
    
    <h2>ğŸ“Š ìš”ì•½</h2>
    <p>ìš”ì•½ ë‚´ìš©...</p>
</div>

<div class="ai-analysis">
    <h2>ğŸ¤– AI ë¶„ì„</h2>
    <div class="analysis-item">
        <h3>AI ìš”ì•½ (100ì ì´ë‚´)</h3>
        <p>ìš”ì•½ ë‚´ìš©...</p>
    </div>
    <div class="analysis-item">
        <h3>ì‹ ë¢°ë„ í‰ê°€ (5ì  ë§Œì )</h3>
        <p>í‰ì : â­â­â­â­â­ (5/5)</p>
        <p>í‰ê°€ ê·¼ê±°: ...</p>
    </div>
    <div class="analysis-item">
        <h3>SEO ìµœì í™” ì ìˆ˜ (10ì  ë§Œì )</h3>
        <p>í‰ì : ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ (10/10)</p>
        <p>ìµœì í™” ê·¼ê±°: ...</p>
    </div>
</div>
```

ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª…ë„ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.
"""

        # API í˜¸ì¶œ
        for attempt in range(MAX_RETRIES):
            try:
                response = await client.chat.completions.create(
                    model=settings.openai_model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ SEO ì „ë¬¸ê°€ì´ì ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤. ê³ í’ˆì§ˆì˜ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=settings.openai_max_tokens,
                    temperature=0.7
                )
                
                generated_content = response.choices[0].message.content.strip()
                
                # HTML íƒœê·¸ ì¶”ì¶œ
                title_match = re.search(r'<h1[^>]*>(.*?)</h1>', generated_content, re.IGNORECASE | re.DOTALL)
                meta_match = re.search(r'<meta[^>]*name="description"[^>]*content="([^"]*)"', generated_content, re.IGNORECASE)
                
                title = title_match.group(1).strip() if title_match else f"{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}"
                meta_description = meta_match.group(1).strip() if meta_match else f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                
                # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                clean_content = re.sub(r'<[^>]+>', '', generated_content)
                word_count = len(clean_content.split())
                
                # AI ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
                ai_analysis = _extract_ai_analysis(generated_content)
                
                # ê°€ì´ë“œë¼ì¸ ì ìš© ë¶„ì„
                guidelines_analysis = _analyze_guidelines_application(generated_content, rule_guidelines)
                
                result = {
                    'post': generated_content,
                    'title': title,
                    'meta_description': meta_description,
                    'keywords': keywords,
                    'word_count': word_count,
                    'content_length': content_length,
                    'ai_mode': ai_mode or 'openai',
                    'ai_analysis': ai_analysis,
                    'guidelines_analysis': guidelines_analysis
                }
                
                # ì„±ëŠ¥ ë¡œê¹…
                end_time = time.time()
                logger.info(f"í–¥ìƒëœ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {end_time - start_time:.2f}ì´ˆ")
                
                return result
                
            except Exception as e:
                logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES - 1:
                    raise ContentGenerationError(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
                await asyncio.sleep(1)
                
    except Exception as e:
        logger.error(f"í–¥ìƒëœ ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        raise ContentGenerationError(f"í–¥ìƒëœ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}")

def _extract_ai_analysis(content: str) -> Dict:
    """AI ë¶„ì„ ê²°ê³¼ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    analysis = {
        'ai_summary': '',
        'trust_score': 0,
        'seo_score': 0,
        'trust_reason': '',
        'seo_reason': ''
    }
    
    try:
        # AI ìš”ì•½ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­)
        summary_patterns = [
            r'<h3>AI ìš”ì•½.*?</h3>\s*<p>(.*?)</p>',
            r'<h3>AI ìš”ì•½.*?</h3>\s*<p>(.*?)(?=<h3>|<div|</div>)',
            r'AI ìš”ì•½.*?<p>(.*?)</p>',
            r'AI ìš”ì•½.*?<p>(.*?)(?=<h3>|<div|</div>)'
        ]
        
        for pattern in summary_patterns:
            summary_match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
            if summary_match:
                summary_text = summary_match.group(1).strip()
                # HTML íƒœê·¸ ì œê±°
                summary_text = re.sub(r'<[^>]+>', '', summary_text)
                analysis['ai_summary'] = summary_text
                break
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
        trust_patterns = [
            r'í‰ì :\s*â­+.*?\((\d+)/5\)',
            r'ì‹ ë¢°ë„.*?\((\d+)/5\)',
            r'ì‹ ë¢°ë„.*?(\d+)/5'
        ]
        
        for pattern in trust_patterns:
            trust_match = re.search(pattern, content, re.IGNORECASE)
            if trust_match:
                analysis['trust_score'] = int(trust_match.group(1))
                break
        
        # SEO ì ìˆ˜ ì¶”ì¶œ
        seo_patterns = [
            r'í‰ì :\s*ğŸ”¥+.*?\((\d+)/10\)',
            r'SEO.*?\((\d+)/10\)',
            r'SEO.*?(\d+)/10'
        ]
        
        for pattern in seo_patterns:
            seo_match = re.search(pattern, content, re.IGNORECASE)
            if seo_match:
                analysis['seo_score'] = int(seo_match.group(1))
                break
        
        # í‰ê°€ ê·¼ê±° ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
        trust_reason_patterns = [
            r'í‰ê°€ ê·¼ê±°:\s*(.*?)(?=<h3>|<div|</div>|$)',
            r'ì‹ ë¢°ë„.*?ê·¼ê±°:\s*(.*?)(?=<h3>|<div|</div>|$)'
        ]
        
        for pattern in trust_reason_patterns:
            trust_reason_match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
            if trust_reason_match:
                reason_text = trust_reason_match.group(1).strip()
                reason_text = re.sub(r'<[^>]+>', '', reason_text)
                analysis['trust_reason'] = reason_text
                break
        
        seo_reason_patterns = [
            r'ìµœì í™” ê·¼ê±°:\s*(.*?)(?=<h3>|<div|</div>|$)',
            r'SEO.*?ê·¼ê±°:\s*(.*?)(?=<h3>|<div|</div>|$)'
        ]
        
        for pattern in seo_reason_patterns:
            seo_reason_match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
            if seo_reason_match:
                reason_text = seo_reason_match.group(1).strip()
                reason_text = re.sub(r'<[^>]+>', '', reason_text)
                analysis['seo_reason'] = reason_text
                break
            
    except Exception as e:
        logger.error(f"AI ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return analysis

async def _create_enhanced_blog_post_with_gemini(text: str, keywords: str, rule_guidelines: Optional[list] = None, content_length: str = "5000", ai_mode: Optional[str] = None) -> Dict:
    """
    Gemini 2.0 Flash APIë¥¼ ì‚¬ìš©í•˜ì—¬ í–¥ìƒëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        import httpx
        
        # Gemini API í‚¤ í™•ì¸
        from .translator import get_gemini_api_key
        api_key = get_gemini_api_key()
        if not api_key:
            raise ContentGenerationError("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì½˜í…ì¸  ê¸¸ì´ ì„¤ì •
        target_length = int(content_length) if content_length.isdigit() else 5000
        
        # ê·œì¹™ ê°€ì´ë“œë¼ì¸ ì²˜ë¦¬
        rules_text = ""
        if rule_guidelines:
            rules_text = "\n".join([f"- {rule}" for rule in rule_guidelines])
        
        # ì½˜í…ì¸  ìŠ¤íƒ€ì¼ë³„ ê°€ì´ë“œë¼ì¸ ì¶”ê°€
        style_guidelines = ""
        if ai_mode:
            if ai_mode == "ë‰´ìŠ¤":
                style_guidelines = """
ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ê°ê´€ì ì´ê³  ì‚¬ì‹¤ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±
- 5W1H (ëˆ„ê°€, ì–¸ì œ, ì–´ë””ì„œ, ë¬´ì—‡ì„, ì™œ, ì–´ë–»ê²Œ) í¬í•¨
- ìµœì‹ ì„±ê³¼ ì‹œì˜ì„± ê°•ì¡°
- ìš”ì•½: í•µì‹¬ ì‚¬ì‹¤ë§Œ ê°„ê²°í•˜ê²Œ (300ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì‹œê°„ìˆœ ë˜ëŠ” ì¤‘ìš”ë„ìˆœìœ¼ë¡œ êµ¬ì„±
- ê°œì¸ì  ì˜ê²¬ ë°°ì œ, ê°ê´€ì  ì„œìˆ 
"""
            elif ai_mode == "ë¦¬ë·°":
                style_guidelines = """
ë¦¬ë·° ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ì¥ë‹¨ì ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„œìˆ 
- ê°œì¸ì  ê²½í—˜ê³¼ ì²´í—˜ ì¤‘ì‹¬
- êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±° ì œì‹œ
- ìš”ì•½: í•µì‹¬ í‰ê°€ì™€ ì¶”ì²œ ì—¬ë¶€ (400ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì¥ì , ë‹¨ì , ê²°ë¡  ìˆœìœ¼ë¡œ êµ¬ì„±
- ì†”ì§í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤ ìœ ì§€
"""
            elif ai_mode == "ê°€ì´ë“œ":
                style_guidelines = """
ê°€ì´ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…
- ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì •ë³´ ì œê³µ
- ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸íˆ ì„¤ëª…
- ìš”ì•½: í•µì‹¬ ë‹¨ê³„ì™€ ëª©í‘œ (350ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ë‹¨ê³„ë³„ ìˆœì„œëŒ€ë¡œ êµ¬ì„±
- ì²´í¬ë¦¬ìŠ¤íŠ¸ë‚˜ íŒ í¬í•¨
"""
            elif ai_mode == "ìš”ì•½":
                style_guidelines = """
ìš”ì•½ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬
- ë¶ˆí•„ìš”í•œ ì„¤ëª… ì œê±°
- ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥
- ìš”ì•½: í•µì‹¬ í¬ì¸íŠ¸ë§Œ ê°„ê²°í•˜ê²Œ (250ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ì¤‘ìš”ë„ìˆœìœ¼ë¡œ í•µì‹¬ë§Œ ë‚˜ì—´
- ë¹ ë¥¸ ì •ë³´ ì „ë‹¬ì— ìµœì í™”
"""
            elif ai_mode == "ë¸”ë¡œê·¸":
                style_guidelines = """
ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:
- ê°œì¸ì  ì¸ì‚¬ì´íŠ¸ì™€ ê²½í—˜ ì¤‘ì‹¬
- ë…ìì™€ì˜ ì†Œí†µí•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±
- ì‹¤ìš©ì  ì¡°ì–¸ê³¼ ê°œì¸ì  ê²¬í•´ í¬í•¨
- ìš”ì•½: ê°œì¸ì  ê´€ì ê³¼ í•µì‹¬ ë©”ì‹œì§€ (400ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ê²½í—˜ë‹´, ì¸ì‚¬ì´íŠ¸, ì¡°ì–¸ ìˆœìœ¼ë¡œ êµ¬ì„±
- ì¹œê·¼í•˜ê³  ì†”ì§í•œ ì–´ì¡° ìœ ì§€
"""
            elif ai_mode == "enhanced":
                style_guidelines = """
í–¥ìƒëœ ëª¨ë“œ ê°€ì´ë“œë¼ì¸:
- AI ë¶„ì„ê³¼ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ í¬í•¨
- ì‹¬ì¸µì  ë¶„ì„ê³¼ ì „ë¬¸ì  ê´€ì 
- ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì¢…í•©ì  ë¶„ì„
- ìš”ì•½: AI ë¶„ì„ ê²°ê³¼ì™€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (500ì ì´ë‚´)
- ì£¼ìš” ë‚´ìš©: ë¶„ì„, ì¸ì‚¬ì´íŠ¸, ì „ë§ ìˆœìœ¼ë¡œ êµ¬ì„±
- ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
"""
        
        # ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ê°€ì´ë“œë¼ì¸
        summary_guidelines = """
ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ê°€ì´ë“œë¼ì¸:
- ìš”ì•½: ì™„ë²½í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±, 500ì ì´ë‚´
- ì£¼ìš” ë‚´ìš©: í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ë¶„
- í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- ë…ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°
- ê° ì„¹ì…˜ë³„ë¡œ ëª…í™•í•œ ì œëª© ì‚¬ìš©
"""
        
        # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEO ìµœì í™”ëœ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
{text}

ì£¼ìš” í‚¤ì›Œë“œ: {keywords}

ìš”êµ¬ì‚¬í•­:
- ëª©í‘œ ê¸¸ì´: ì•½ {target_length}ì
- SEO ìµœì í™”: í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- êµ¬ì¡°: ì œëª©, ì†Œì œëª©, ë³¸ë¬¸, ê²°ë¡  í¬í•¨
- HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶”ê°€ ê·œì¹™:
{rules_text}

{style_guidelines}

{summary_guidelines}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

```html
<h1>ì œëª©</h1>
<meta name="description" content="ë©”íƒ€ ì„¤ëª…">

<div class="content-intro">
    <p>ì†Œê°œ ë‚´ìš©...</p>
</div>

<div class="ai-keywords">
    <h2>ğŸ¤– AI ì¶”ì²œ í‚¤ì›Œë“œ</h2>
    <ul>
        <li>í‚¤ì›Œë“œ1</li>
        <li>í‚¤ì›Œë“œ2</li>
        ...
    </ul>
</div>

<div class="main-content">
    <h2>ğŸ“‹ ì£¼ìš” ë‚´ìš©</h2>
    <p>ì£¼ìš” ë‚´ìš©...</p>
    
    <h2>ğŸ” í•µì‹¬ í¬ì¸íŠ¸</h2>
    <ul>
        <li>í•µì‹¬ í¬ì¸íŠ¸ 1</li>
        <li>í•µì‹¬ í¬ì¸íŠ¸ 2</li>
        ...
    </ul>
    
    <h2>ğŸ’¡ ì‹¤ìš©ì ì¸ íŒ</h2>
    <div class="tips-container">
        <div class="tip-item">
            <h3>íŒ 1</h3>
            <p>íŒ ë‚´ìš©...</p>
        </div>
        ...
    </div>
    
    <h2>ğŸ“Š ìš”ì•½</h2>
    <p>ìš”ì•½ ë‚´ìš©...</p>
</div>

<div class="ai-analysis">
    <h2>ğŸ¤– AI ë¶„ì„</h2>
    <div class="analysis-item">
        <h3>AI ìš”ì•½ (100ì ì´ë‚´)</h3>
        <p>ìš”ì•½ ë‚´ìš©...</p>
    </div>
    <div class="analysis-item">
        <h3>ì‹ ë¢°ë„ í‰ê°€ (5ì  ë§Œì )</h3>
        <p>í‰ì : â­â­â­â­â­ (5/5)</p>
        <p>í‰ê°€ ê·¼ê±°: ...</p>
    </div>
    <div class="analysis-item">
        <h3>SEO ìµœì í™” ì ìˆ˜ (10ì  ë§Œì )</h3>
        <p>í‰ì : ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ (10/10)</p>
        <p>ìµœì í™” ê·¼ê±°: ...</p>
    </div>
</div>
```

ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª…ë„ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        async with httpx.AsyncClient(timeout=30) as client:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
            payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 8192
                }
            }
            
            response = await client.post(url, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and result['candidates']:
                    generated_content = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    
                    # HTML íƒœê·¸ ì¶”ì¶œ
                    title_match = re.search(r'<h1[^>]*>(.*?)</h1>', generated_content, re.IGNORECASE | re.DOTALL)
                    meta_match = re.search(r'<meta[^>]*name="description"[^>]*content="([^"]*)"', generated_content, re.IGNORECASE)
                    
                    title = title_match.group(1).strip() if title_match else f"{keywords.split(',')[0] if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}"
                    meta_description = meta_match.group(1).strip() if meta_match else f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                    
                    # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    clean_content = re.sub(r'<[^>]+>', '', generated_content)
                    word_count = len(clean_content.split())
                    
                    # AI ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
                    ai_analysis = _extract_ai_analysis(generated_content)
                    
                    # ê°€ì´ë“œë¼ì¸ ì ìš© ë¶„ì„
                    guidelines_analysis = _analyze_guidelines_application(generated_content, rule_guidelines)
                    
                    return {
                        'post': generated_content,
                        'title': title,
                        'meta_description': meta_description,
                        'keywords': keywords,
                        'word_count': word_count,
                        'content_length': content_length,
                        'ai_mode': ai_mode or 'gemini_2_0_flash',
                        'ai_analysis': ai_analysis,
                        'guidelines_analysis': guidelines_analysis
                    }
                else:
                    raise ContentGenerationError("Gemini API ì‘ë‹µì— ìƒì„± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                error_detail = response.text
                logger.error(f"Gemini API ì˜¤ë¥˜: {response.status_code} - {error_detail}")
                raise ContentGenerationError(f"Gemini API ì˜¤ë¥˜: {response.status_code}")
                
    except Exception as e:
        logger.error(f"Gemini í–¥ìƒëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        raise ContentGenerationError(f"Gemini í–¥ìƒëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def _generate_enhanced_default_template(text: str, keywords: str, rule_guidelines: Optional[List[str]] = None, content_length: str = "3000", ai_mode: Optional[str] = None) -> Dict:
    """
    í–¥ìƒëœ ê¸°ëŠ¥ì„ í¬í•¨í•œ ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„±
    """
    # ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ
    if not keywords:
        keywords = _extract_default_keywords(text)
    
    # ì œëª© ìƒì„±
    title = f"{keywords.split(',')[0].strip() if keywords else 'AI ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'}ì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œ"
    
    # í…ìŠ¤íŠ¸ ìš”ì•½ (1000ì ì´ë‚´ë¡œ ì™„ë²½í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬)
    def create_summary(text_content, max_length=1000):
        """ì£¼ìš” ë‚´ìš©ì˜ ì „ì²´ í…ìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì••ì¶•í•˜ì—¬ 1000ì ì´ë‚´ë¡œ ì •ë¦¬"""
        if len(text_content) <= max_length:
            return text_content
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text_content)
        summary_sentences = []
        current_length = 0
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œ ì¶”ê°€
            if not sentence.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                sentence += '.'
            
            if current_length + len(sentence) <= max_length:
                summary_sentences.append(sentence)
                current_length += len(sentence)
            else:
                break
        
        return ' '.join(summary_sentences)
    
    summary = create_summary(text, 1000)
    
    # ì£¼ìš” ë‚´ìš© ìƒì„± í•¨ìˆ˜
    def create_main_content(text_content, target_length):
        """URL ì…ë ¥ ë˜ëŠ” ì…ë ¥ í…ŒìŠ¤íŠ¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ 'ì½˜í…ì¸  ë¶„ëŸ‰'ì— ë”°ë¼ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¬¸ì¥í˜•ìœ¼ë¡œ ìƒì„±"""
        try:
            target_length_int = int(target_length) if target_length.isdigit() else 3000
            
            # ì½˜í…ì¸  ê¸¸ì´ì— ë”°ë¥¸ ì£¼ìš” ë‚´ìš© ìƒì„±
            if len(text_content) < 500:
                # ì§§ì€ ì½˜í…ì¸ : ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜ ë¬¸ì¥í˜•ìœ¼ë¡œ ì •ë¦¬
                sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text_content)
                clean_sentences = []
                for sentence in sentences:
                    sentence = sentence.strip()
                    if sentence and not sentence.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                        sentence += '.'
                    if sentence:
                        clean_sentences.append(sentence)
                return ' '.join(clean_sentences)
            elif len(text_content) < 1500:
                # ì¤‘ê°„ ê¸¸ì´: ìš”ì•½ + ì¶”ê°€ ì„¤ëª…
                return f"{summary} ì´ ë‚´ìš©ì€ {keywords.split(',')[0].strip() if keywords else 'ì£¼ì œ'}ì— ëŒ€í•œ í•µì‹¬ ì •ë³´ë¥¼ ë‹´ê³  ìˆìœ¼ë©°, ë” ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ì„¹ì…˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            else:
                # ê¸´ ì½˜í…ì¸ : êµ¬ì¡°í™”ëœ ì£¼ìš” ë‚´ìš©
                sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text_content)
                main_sentences = []
                current_length = 0
                max_main_length = min(target_length_int // 3, 800)  # ì£¼ìš” ë‚´ìš©ì€ ì „ì²´ì˜ 1/3 ì´í•˜
                
                for sentence in sentences:
                    sentence = sentence.strip()
                    if not sentence:
                        continue
                    
                    if not sentence.endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                        sentence += '.'
                    
                    if current_length + len(sentence) <= max_main_length:
                        main_sentences.append(sentence)
                        current_length += len(sentence)
                    else:
                        break
                
                main_content = ' '.join(main_sentences)
                if len(main_content) < len(text_content):
                    main_content += f" ì´ ì™¸ì—ë„ {keywords.split(',')[0].strip() if keywords else 'ì£¼ì œ'}ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì •ë³´ì™€ ë¶„ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                
                return main_content
        except Exception as e:
            logger.error(f"ì£¼ìš” ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return summary
    
    # AI ì¶”ì²œ í‚¤ì›Œë“œ (ëª…ì‚¬ ì¤‘ì‹¬, ìµœëŒ€ 10ê°œ)
    ai_keywords = _extract_ai_keywords(text, keywords)
    
    # í–¥ìƒëœ HTML ì½˜í…ì¸  ìƒì„±
    content = f"""
<h1>{title}</h1>
<meta name="description" content="{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.">

<div class="content-intro">
    <p>ì´ ê¸€ì—ì„œëŠ” <strong>{keywords}</strong>ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.</p>
</div>

<div class="ai-keywords">
    <h2>ğŸ¤– AI ì¶”ì²œ í‚¤ì›Œë“œ</h2>
    <ul>
        {''.join([f'<li>{keyword.strip()}</li>' for keyword in ai_keywords[:10]])}
    </ul>
</div>

    <div class="main-content">
        <h2>ğŸ“ ìš”ì•½</h2>
        <p>{summary}</p>
        
        <h2>ğŸ“‹ ì£¼ìš” ë‚´ìš©</h2>
        <p>{create_main_content(text, content_length)}</p>
    
    <h2>ğŸ” í•µì‹¬ í¬ì¸íŠ¸</h2>
    <ul>
        <li><strong>ì²« ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> {keywords.split(',')[0].strip()}ì˜ ê¸°ë³¸ ê°œë…ê³¼ ì¤‘ìš”ì„±</li>
        <li><strong>ë‘ ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> ì‹¤ì œ ì ìš© ë°©ë²•ê³¼ ì‚¬ë¡€</li>
        <li><strong>ì„¸ ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> ì£¼ì˜ì‚¬í•­ê³¼ ëª¨ë²” ì‚¬ë¡€</li>
        <li><strong>ë„¤ ë²ˆì§¸ ì¤‘ìš”í•œ í¬ì¸íŠ¸:</strong> ë¯¸ë˜ ì „ë§ê³¼ ë°œì „ ë°©í–¥</li>
    </ul>
    
    <h2>ğŸ’¡ ì‹¤ìš©ì ì¸ íŒ</h2>
    <div class="tips-container">
        <div class="tip-item">
            <h3>íŒ 1: íš¨ê³¼ì ì¸ í™œìš©</h3>
            <p>{keywords.split(',')[0].strip()}ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”.</p>
        </div>
        <div class="tip-item">
            <h3>íŒ 2: ì£¼ì˜ì‚¬í•­</h3>
            <p>ì¼ë°˜ì ì¸ ì‹¤ìˆ˜ì™€ í”¼í•´ì•¼ í•  í•¨ì •ì— ëŒ€í•´ ì•Œì•„ë³´ì„¸ìš”.</p>
        </div>
        <div class="tip-item">
            <h3>íŒ 3: ìµœì í™” ë°©ë²•</h3>
            <p>ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”.</p>
        </div>
    </div>
    
    <h2>ğŸ“Š ìš”ì•½</h2>
    <p>ì´ ê¸€ì„ í†µí•´ {keywords.split(',')[0].strip()}ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ , ì‹¤ì œ ìƒí™©ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì§€ì‹ì„ ì–»ì—ˆìŠµë‹ˆë‹¤.</p>
</div>

    <div class="ai-analysis">
        <h2>ğŸ¤– AI ë¶„ì„</h2>
        <div class="analysis-item">
            <h3>AI ìš”ì•½ (1000ì ì´ë‚´)</h3>
            <p>{summary[:1000]}{'...' if len(summary) > 1000 else ''}</p>
        </div>
    <div class="analysis-item">
        <h3>ì‹ ë¢°ë„ í‰ê°€ (5ì  ë§Œì )</h3>
        <p>í‰ì : â­â­â­â­â­ (5/5)</p>
        <p>í‰ê°€ ê·¼ê±°: ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ì™€ ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.</p>
    </div>
    <div class="analysis-item">
        <h3>SEO ìµœì í™” ì ìˆ˜ (10ì  ë§Œì )</h3>
        <p>í‰ì : ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ (10/10)</p>
        <p>ìµœì í™” ê·¼ê±°: í‚¤ì›Œë“œ ìµœì í™”, êµ¬ì¡°í™”ëœ ì½˜í…ì¸ , ë©”íƒ€ ì„¤ëª…, ì‚¬ìš©ì ì¹œí™”ì  ë ˆì´ì•„ì›ƒì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.</p>
    </div>
</div>

<style>
.content-intro {{ background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0; }}
.ai-keywords {{ background: #e8f5e8; padding: 1rem; border-radius: 8px; margin: 1rem 0; }}
.main-content {{ line-height: 1.6; }}
.tips-container {{ display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 1rem; margin: 1rem 0; }}
.tip-item {{ background: #e3f2fd; padding: 1rem; border-radius: 8px; border-left: 4px solid #2196f3; }}
.ai-analysis {{ background: #fff3e0; padding: 1rem; border-radius: 8px; margin: 1rem 0; }}
.analysis-item {{ margin: 1rem 0; padding: 0.5rem; background: white; border-radius: 4px; }}
</style>
"""
    
    # ë‹¨ì–´ ìˆ˜ ê³„ì‚°
    text_content = re.sub(r'<[^>]+>', '', content)
    word_count = len(text_content.split())
    
    # AI ë¶„ì„ ê²°ê³¼
    ai_analysis = {
        'ai_summary': summary[:1000] + ('...' if len(summary) > 1000 else ''),
        'trust_score': 5,
        'seo_score': 10,
        'trust_reason': 'ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ì™€ ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.',
        'seo_reason': 'í‚¤ì›Œë“œ ìµœì í™”, êµ¬ì¡°í™”ëœ ì½˜í…ì¸ , ë©”íƒ€ ì„¤ëª…, ì‚¬ìš©ì ì¹œí™”ì  ë ˆì´ì•„ì›ƒì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.'
    }
    
    # ê°€ì´ë“œë¼ì¸ ì ìš© ë¶„ì„
    guidelines_analysis = _analyze_guidelines_application(content, rule_guidelines)
    
    return {
        'post': content,
        'title': title,
        'meta_description': f"{keywords}ì— ëŒ€í•œ í¬ê´„ì ì¸ ì •ë³´ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
        'keywords': keywords,
        'word_count': word_count,
        'content_length': content_length,
        'ai_mode': ai_mode or 'default',
        'ai_analysis': ai_analysis,
        'guidelines_analysis': guidelines_analysis
    }

def _extract_ai_keywords(text: str, existing_keywords: str) -> List[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ AI ì¶”ì²œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ëª…ì‚¬ ì¤‘ì‹¬, ìµœëŒ€ 10ê°œ)
    """
    try:
        # ê¸°ì¡´ í‚¤ì›Œë“œì™€ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©
        combined_text = f"{existing_keywords} {text}"
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§ (ëª…ì‚¬ ì¤‘ì‹¬)
        import re
        
        # í•œêµ­ì–´ ëª…ì‚¬ íŒ¨í„´ (ê°„ë‹¨í•œ êµ¬í˜„)
        korean_nouns = re.findall(r'[ê°€-í£]+', combined_text)
        
        # ì˜ì–´ ëª…ì‚¬ íŒ¨í„´
        english_words = re.findall(r'\b[a-zA-Z]{3,}\b', combined_text)
        
        # í‚¤ì›Œë“œ í›„ë³´ ìƒì„±
        candidates = []
        
        # ê¸°ì¡´ í‚¤ì›Œë“œ ì¶”ê°€
        if existing_keywords:
            candidates.extend([kw.strip() for kw in existing_keywords.split(',')])
        
        # í•œêµ­ì–´ ëª…ì‚¬ ì¶”ê°€ (ê¸¸ì´ê°€ 2ì ì´ìƒì¸ ê²ƒë§Œ)
        candidates.extend([noun for noun in korean_nouns if len(noun) >= 2])
        
        # ì˜ì–´ ë‹¨ì–´ ì¶”ê°€
        candidates.extend(english_words)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_candidates = list(set(candidates))
        unique_candidates.sort(key=len, reverse=True)  # ê¸´ í‚¤ì›Œë“œ ìš°ì„ 
        
        # ìµœëŒ€ 10ê°œ ë°˜í™˜
        return unique_candidates[:10]
        
    except Exception as e:
        logger.error(f"AI í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
        if existing_keywords:
            return [kw.strip() for kw in existing_keywords.split(',')[:10]]
        return ['í‚¤ì›Œë“œ', 'ë¶„ì„', 'ê°€ì´ë“œ']

def _analyze_guidelines_application(content: str, rules: Optional[List[str]] = None) -> Dict:
    """
    ìƒì„±ëœ ì½˜í…ì¸ ì—ì„œ ê°€ì´ë“œë¼ì¸ ì ìš© ì—¬ë¶€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    analysis = {
        'ai_seo_applied': False,
        'aeo_applied': False,
        'geo_applied': False,
        'aio_applied': False,
        'policy_applied': False,
        'structured_data': False,
        'faq_included': False,
        'keywords_optimized': False,
        'headings_structure': False,
        'links_included': False,
        'images_optimized': False,
        'balance_perspective': False
    }
    
    try:
        # AI SEO ë¶„ì„
        if rules and 'AI_SEO' in rules:
            analysis['ai_seo_applied'] = True
            # êµ¬ì¡°í™”ëœ ë°ì´í„° í™•ì¸
            if 'itemscope' in content or 'schema.org' in content:
                analysis['structured_data'] = True
            # í‚¤ì›Œë“œ ìµœì í™” í™•ì¸ (H1, H2 íƒœê·¸)
            if '<h1' in content and '<h2' in content:
                analysis['keywords_optimized'] = True
            # í—¤ë”© êµ¬ì¡° í™•ì¸
            if '<h1' in content and '<h2' in content and '<h3' in content:
                analysis['headings_structure'] = True
            # ë§í¬ í™•ì¸
            if '<a href' in content or 'http' in content:
                analysis['links_included'] = True
            # ì´ë¯¸ì§€ ìµœì í™” í™•ì¸
            if '<img' in content and 'alt=' in content:
                analysis['images_optimized'] = True
        
        # AEO ë¶„ì„
        if rules and 'AEO' in rules:
            analysis['aeo_applied'] = True
            # FAQ í¬í•¨ í™•ì¸
            if 'FAQ' in content or 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸' in content or 'Q&A' in content:
                analysis['faq_included'] = True
        
        # GEO ë¶„ì„
        if rules and 'GEO' in rules:
            analysis['geo_applied'] = True
            # êµ¬ì¡°í™”ëœ ë°ì´í„° í™•ì¸
            if 'itemscope' in content or 'schema.org' in content:
                analysis['structured_data'] = True
        
        # AIO ë¶„ì„
        if rules and 'AIO' in rules:
            analysis['aio_applied'] = True
        
        # ì •ì±… ê· í˜• í™•ì¸
        if 'ì¥ë‹¨ì ' in content or 'ê³ ë ¤ì‚¬í•­' in content or 'ì£¼ì˜ì‚¬í•­' in content or 'ë‹¨ì ' in content:
            analysis['balance_perspective'] = True
            analysis['policy_applied'] = True
            
    except Exception as e:
        logger.error(f"ê°€ì´ë“œë¼ì¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return analysis
