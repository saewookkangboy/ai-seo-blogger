#!/usr/bin/env python3
"""
í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë„êµ¬
ê°œì„ ëœ í¬ë¡¤ëŸ¬ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ë¬¸ì œ ì‚¬ì´íŠ¸ë“¤ì˜ ê°œì„  ìƒí™©ì„ í™•ì¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import time
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any
import requests

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.crawler import EnhancedCrawler
from app.services.google_style_crawler import GoogleStyleCrawler
from app.services.crawler_monitor import crawling_monitor

class CrawlerPerformanceTester:
    """í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.enhanced_crawler = EnhancedCrawler()
        self.google_crawler = GoogleStyleCrawler()
        self.test_results = []
        
        # í…ŒìŠ¤íŠ¸í•  ì‚¬ì´íŠ¸ ëª©ë¡ (ë¬¸ì œê°€ ìˆë˜ ì‚¬ì´íŠ¸ë“¤ í¬í•¨)
        self.test_sites = [
            "https://www.example.com",
            "https://searchengineland.com",
            "https://www.socialmediatoday.com",
            "https://www.facebook.com",
            "https://www.bbc.com",
            "https://moz.com",
            "https://ahrefs.com",
            "https://backlinko.com",
            "https://neilpatel.com",
            "https://www.searchengineland.com/google-core-update-may-2024-447123",
            "https://www.socialmediatoday.com/news/5-ways-to-improve-your-social-media-strategy-in-2024/",
            "https://www.bbc.com/news/technology-12345678",
            "https://moz.com/blog/seo-guide",
            "https://ahrefs.com/blog/seo-tools",
            "https://backlinko.com/seo-techniques",
            "https://neilpatel.com/blog/digital-marketing-strategies/"
        ]
    
    def test_enhanced_crawler(self, url: str) -> Dict[str, Any]:
        """ê°•í™”ëœ í¬ë¡¤ëŸ¬ë¡œ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        success = False
        content_length = 0
        error = ""
        
        try:
            content = self.enhanced_crawler.crawl_url(url, max_retries=3, use_google_style=True)
            if content:
                success = True
                content_length = len(content)
            else:
                error = "ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨"
        except Exception as e:
            error = str(e)
        
        response_time = time.time() - start_time
        
        return {
            "crawler_type": "Enhanced",
            "url": url,
            "success": success,
            "content_length": content_length,
            "response_time": response_time,
            "error": error
        }
    
    def test_google_style_crawler(self, url: str) -> Dict[str, Any]:
        """Google ìŠ¤íƒ€ì¼ í¬ë¡¤ëŸ¬ë¡œ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        success = False
        content_length = 0
        error = ""
        
        try:
            content = self.google_crawler.crawl_url(url, max_retries=3)
            if content:
                success = True
                content_length = len(content)
            else:
                error = "ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨"
        except Exception as e:
            error = str(e)
        
        response_time = time.time() - start_time
        
        return {
            "crawler_type": "Google Style",
            "url": url,
            "success": success,
            "content_length": content_length,
            "response_time": response_time,
            "error": error
        }
    
    def test_traditional_crawler(self, url: str) -> Dict[str, Any]:
        """ê¸°ì¡´ í¬ë¡¤ëŸ¬ë¡œ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        success = False
        content_length = 0
        error = ""
        
        try:
            content = self.enhanced_crawler.crawl_url(url, max_retries=3, use_google_style=False)
            if content:
                success = True
                content_length = len(content)
            else:
                error = "ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨"
        except Exception as e:
            error = str(e)
        
        response_time = time.time() - start_time
        
        return {
            "crawler_type": "Traditional",
            "url": url,
            "success": success,
            "content_length": content_length,
            "response_time": response_time,
            "error": error
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ì‚¬ì´íŠ¸ ìˆ˜: {len(self.test_sites)}")
        print("=" * 60)
        
        all_results = []
        
        for i, url in enumerate(self.test_sites, 1):
            print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i}/{len(self.test_sites)}: {url}")
            
            # 1. ê°•í™”ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
            print("  ğŸ“Š ê°•í™”ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
            enhanced_result = self.test_enhanced_crawler(url)
            all_results.append(enhanced_result)
            
            # 2. Google ìŠ¤íƒ€ì¼ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
            print("  ğŸ“Š Google ìŠ¤íƒ€ì¼ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
            google_result = self.test_google_style_crawler(url)
            all_results.append(google_result)
            
            # 3. ê¸°ì¡´ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
            print("  ğŸ“Š ê¸°ì¡´ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
            traditional_result = self.test_traditional_crawler(url)
            all_results.append(traditional_result)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"    âœ… ê°•í™”ëœ: {'ì„±ê³µ' if enhanced_result['success'] else 'ì‹¤íŒ¨'} ({enhanced_result['content_length']}ì, {enhanced_result['response_time']:.2f}ì´ˆ)")
            print(f"    âœ… Google: {'ì„±ê³µ' if google_result['success'] else 'ì‹¤íŒ¨'} ({google_result['content_length']}ì, {google_result['response_time']:.2f}ì´ˆ)")
            print(f"    âœ… ê¸°ì¡´: {'ì„±ê³µ' if traditional_result['success'] else 'ì‹¤íŒ¨'} ({traditional_result['content_length']}ì, {traditional_result['response_time']:.2f}ì´ˆ)")
            
            # í¬ë¡¤ë§ ê°„ê²©
            time.sleep(1)
        
        # ê²°ê³¼ ë¶„ì„
        analysis = self.analyze_results(all_results)
        
        # ê²°ê³¼ ì €ì¥
        self.save_results(all_results, analysis)
        
        return analysis
    
    def analyze_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        analysis = {
            "total_tests": len(results),
            "crawler_comparison": {},
            "site_performance": {},
            "overall_stats": {}
        }
        
        # í¬ë¡¤ëŸ¬ë³„ í†µê³„
        crawler_stats = {}
        for result in results:
            crawler_type = result["crawler_type"]
            if crawler_type not in crawler_stats:
                crawler_stats[crawler_type] = {
                    "total": 0,
                    "success": 0,
                    "total_content_length": 0,
                    "total_response_time": 0,
                    "errors": []
                }
            
            stats = crawler_stats[crawler_type]
            stats["total"] += 1
            
            if result["success"]:
                stats["success"] += 1
                stats["total_content_length"] += result["content_length"]
            
            stats["total_response_time"] += result["response_time"]
            
            if result["error"]:
                stats["errors"].append(result["error"])
        
        # ì„±ê³µë¥  ë° í‰ê·  ê³„ì‚°
        for crawler_type, stats in crawler_stats.items():
            success_rate = stats["success"] / stats["total"] if stats["total"] > 0 else 0
            avg_content_length = stats["total_content_length"] / stats["success"] if stats["success"] > 0 else 0
            avg_response_time = stats["total_response_time"] / stats["total"] if stats["total"] > 0 else 0
            
            analysis["crawler_comparison"][crawler_type] = {
                "success_rate": round(success_rate, 4),
                "avg_content_length": round(avg_content_length, 2),
                "avg_response_time": round(avg_response_time, 2),
                "total_tests": stats["total"],
                "successful_tests": stats["success"],
                "common_errors": list(set(stats["errors"]))
            }
        
        # ì‚¬ì´íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„
        site_stats = {}
        for i in range(0, len(results), 3):  # 3ê°œ í¬ë¡¤ëŸ¬ ê²°ê³¼ì”© ê·¸ë£¹í™”
            if i + 2 < len(results):
                url = results[i]["url"]
                enhanced = results[i]
                google = results[i + 1]
                traditional = results[i + 2]
                
                site_stats[url] = {
                    "enhanced": {
                        "success": enhanced["success"],
                        "content_length": enhanced["content_length"],
                        "response_time": enhanced["response_time"]
                    },
                    "google": {
                        "success": google["success"],
                        "content_length": google["content_length"],
                        "response_time": google["response_time"]
                    },
                    "traditional": {
                        "success": traditional["success"],
                        "content_length": traditional["content_length"],
                        "response_time": traditional["response_time"]
                    }
                }
        
        analysis["site_performance"] = site_stats
        
        # ì „ì²´ í†µê³„
        total_success = sum(1 for r in results if r["success"])
        total_content_length = sum(r["content_length"] for r in results if r["success"])
        total_response_time = sum(r["response_time"] for r in results)
        
        analysis["overall_stats"] = {
            "total_tests": len(results),
            "total_success": total_success,
            "overall_success_rate": round(total_success / len(results), 4),
            "avg_content_length": round(total_content_length / total_success, 2) if total_success > 0 else 0,
            "avg_response_time": round(total_response_time / len(results), 2)
        }
        
        return analysis
    
    def save_results(self, results: List[Dict[str, Any]], analysis: Dict[str, Any]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"crawler_performance_test_{timestamp}.json"
        
        output = {
            "test_timestamp": datetime.now().isoformat(),
            "test_sites": self.test_sites,
            "detailed_results": results,
            "analysis": analysis
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def print_summary(self, analysis: Dict[str, Any]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        # ì „ì²´ í†µê³„
        overall = analysis["overall_stats"]
        print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
        print(f"  â€¢ ì´ í…ŒìŠ¤íŠ¸: {overall['total_tests']}íšŒ")
        print(f"  â€¢ ì„±ê³µ: {overall['total_success']}íšŒ")
        print(f"  â€¢ ì „ì²´ ì„±ê³µë¥ : {overall['overall_success_rate']:.1%}")
        print(f"  â€¢ í‰ê·  ì½˜í…ì¸  ê¸¸ì´: {overall['avg_content_length']:.0f}ì")
        print(f"  â€¢ í‰ê·  ì‘ë‹µ ì‹œê°„: {overall['avg_response_time']:.2f}ì´ˆ")
        
        # í¬ë¡¤ëŸ¬ë³„ ë¹„êµ
        print(f"\nğŸ” í¬ë¡¤ëŸ¬ë³„ ì„±ëŠ¥ ë¹„êµ:")
        for crawler_type, stats in analysis["crawler_comparison"].items():
            print(f"  â€¢ {crawler_type}:")
            print(f"    - ì„±ê³µë¥ : {stats['success_rate']:.1%}")
            print(f"    - í‰ê·  ì½˜í…ì¸  ê¸¸ì´: {stats['avg_content_length']:.0f}ì")
            print(f"    - í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.2f}ì´ˆ")
            if stats['common_errors']:
                print(f"    - ì£¼ìš” ì˜¤ë¥˜: {', '.join(stats['common_errors'][:3])}")
        
        # ê°œì„  íš¨ê³¼ ë¶„ì„
        enhanced = analysis["crawler_comparison"].get("Enhanced", {})
        traditional = analysis["crawler_comparison"].get("Traditional", {})
        
        if enhanced and traditional:
            success_improvement = enhanced["success_rate"] - traditional["success_rate"]
            content_improvement = enhanced["avg_content_length"] - traditional["avg_content_length"]
            
            print(f"\nğŸš€ ê°œì„  íš¨ê³¼:")
            print(f"  â€¢ ì„±ê³µë¥  ê°œì„ : {success_improvement:+.1%}")
            print(f"  â€¢ ì½˜í…ì¸  ê¸¸ì´ ê°œì„ : {content_improvement:+.0f}ì")
        
        # ë¬¸ì œ ì‚¬ì´íŠ¸ ë¶„ì„
        problem_sites = []
        for url, stats in analysis["site_performance"].items():
            if not any([stats["enhanced"]["success"], stats["google"]["success"], stats["traditional"]["success"]]):
                problem_sites.append(url)
        
        if problem_sites:
            print(f"\nâš ï¸  ì—¬ì „íˆ ë¬¸ì œê°€ ìˆëŠ” ì‚¬ì´íŠ¸:")
            for site in problem_sites:
                print(f"  â€¢ {site}")
        else:
            print(f"\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‚¬ì´íŠ¸ì—ì„œ ìµœì†Œ í•˜ë‚˜ì˜ í¬ë¡¤ëŸ¬ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”§ í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë„êµ¬")
    print("ê°œì„ ëœ í¬ë¡¤ëŸ¬ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.")
    
    tester = CrawlerPerformanceTester()
    
    try:
        # ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        analysis = tester.run_comprehensive_test()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        tester.print_summary(analysis)
        
        # ê¸°ì¡´ í†µê³„ì™€ ë¹„êµ
        print(f"\nğŸ“Š ê¸°ì¡´ í¬ë¡¤ë§ í†µê³„ì™€ ë¹„êµ:")
        try:
            overall_stats = crawling_monitor.get_overall_stats()
            print(f"  â€¢ ê¸°ì¡´ ì„±ê³µë¥ : {overall_stats['success_rate']:.1%}")
            print(f"  â€¢ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ : {analysis['overall_stats']['overall_success_rate']:.1%}")
            
            improvement = analysis['overall_stats']['overall_success_rate'] - overall_stats['success_rate']
            print(f"  â€¢ ê°œì„  íš¨ê³¼: {improvement:+.1%}")
        except Exception as e:
            print(f"  â€¢ ê¸°ì¡´ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 