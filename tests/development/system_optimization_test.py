#!/usr/bin/env python3
"""
ì „ì²´ ì‹œìŠ¤í…œ ìµœì í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì„±ëŠ¥, ì•ˆì •ì„±, ê¸°ëŠ¥ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
"""
import requests
import json
import time
import psutil
import os
import sqlite3
from datetime import datetime, timedelta
import threading
import concurrent.futures

class SystemOptimizationTest:
    def __init__(self):
        self.base_url = "http://localhost:8000"
        self.test_results = {}
        self.start_time = time.time()
        
    def log(self, message, level="INFO"):
        """ë¡œê·¸ ì¶œë ¥"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {level}: {message}")
    
    def test_api_endpoints(self):
        """API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        self.log("ğŸš€ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        endpoints = [
            "/",
            "/admin",
            "/api/v1/posts",
            "/api/v1/keywords", 
            "/api/v1/stats/dashboard",
            "/api/v1/system/uptime",
            "/api/v1/system/db-size",
            "/api/v1/system/api-response-time",
            "/api/v1/system/log-files",
            "/api/v1/feature-updates/history",
            "/api/v1/news-archive/"
        ]
        
        results = {}
        total_time = 0
        
        for endpoint in endpoints:
            try:
                start_time = time.time()
                response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # ms
                total_time += response_time
                
                if response.status_code == 200:
                    results[endpoint] = {
                        "status": "success",
                        "response_time": response_time,
                        "status_code": response.status_code
                    }
                    self.log(f"âœ… {endpoint}: {response_time:.2f}ms")
                else:
                    results[endpoint] = {
                        "status": "error",
                        "response_time": response_time,
                        "status_code": response.status_code
                    }
                    self.log(f"âŒ {endpoint}: {response.status_code} ({response_time:.2f}ms)")
                    
            except Exception as e:
                results[endpoint] = {
                    "status": "error",
                    "response_time": 0,
                    "error": str(e)
                }
                self.log(f"âŒ {endpoint}: {e}")
        
        avg_response_time = total_time / len(endpoints) if endpoints else 0
        success_count = sum(1 for r in results.values() if r["status"] == "success")
        
        self.test_results["api_endpoints"] = {
            "total_endpoints": len(endpoints),
            "success_count": success_count,
            "success_rate": (success_count / len(endpoints)) * 100,
            "average_response_time": avg_response_time,
            "details": results
        }
        
        self.log(f"ğŸ“Š API í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(endpoints)} ì„±ê³µ, í‰ê·  ì‘ë‹µì‹œê°„: {avg_response_time:.2f}ms")
    
    def test_database_performance(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.log("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ í¬ê¸° í™•ì¸
            db_path = "news_archive.db"
            if os.path.exists(db_path):
                db_size = os.path.getsize(db_path) / 1024  # KB
            else:
                db_size = 0
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
            start_time = time.time()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchall()
            table_query_time = (time.time() - start_time) * 1000
            
            # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            table_stats = {}
            total_records = 0
            
            for table in tables:
                table_name = table[0]
                start_time = time.time()
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                count = cursor.fetchone()[0]
                query_time = (time.time() - start_time) * 1000
                
                table_stats[table_name] = {
                    "record_count": count,
                    "query_time": query_time
                }
                total_records += count
            
            conn.close()
            
            self.test_results["database"] = {
                "db_size_kb": db_size,
                "table_count": len(tables),
                "total_records": total_records,
                "table_query_time": table_query_time,
                "table_stats": table_stats
            }
            
            self.log(f"ğŸ“Š DB í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(tables)}ê°œ í…Œì´ë¸”, {total_records}ê°œ ë ˆì½”ë“œ, í¬ê¸°: {db_size:.2f}KB")
            
        except Exception as e:
            self.log(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            self.test_results["database"] = {"error": str(e)}
    
    def test_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        self.log("ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
            memory = psutil.virtual_memory()
            
            # í”„ë¡œì„¸ìŠ¤ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            process = psutil.Process()
            process_memory = process.memory_info()
            
            self.test_results["memory"] = {
                "total_memory_gb": memory.total / (1024**3),
                "available_memory_gb": memory.available / (1024**3),
                "used_memory_gb": memory.used / (1024**3),
                "memory_percent": memory.percent,
                "process_memory_mb": process_memory.rss / (1024**2)
            }
            
            self.log(f"ğŸ“Š ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ì „ì²´ {memory.total/(1024**3):.1f}GB, ì‚¬ìš©ë¥ : {memory.percent:.1f}%")
            
        except Exception as e:
            self.log(f"âŒ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            self.test_results["memory"] = {"error": str(e)}
    
    def test_cpu_usage(self):
        """CPU ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        self.log("âš¡ CPU ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            # CPU ì‚¬ìš©ë¥  ì¸¡ì • (5ì´ˆê°„)
            cpu_percentages = []
            for _ in range(5):
                cpu_percentages.append(psutil.cpu_percent(interval=1))
            
            avg_cpu = sum(cpu_percentages) / len(cpu_percentages)
            max_cpu = max(cpu_percentages)
            
            self.test_results["cpu"] = {
                "average_cpu_percent": avg_cpu,
                "max_cpu_percent": max_cpu,
                "cpu_cores": psutil.cpu_count(),
                "cpu_freq_mhz": psutil.cpu_freq().current if psutil.cpu_freq() else 0
            }
            
            self.log(f"ğŸ“Š CPU í…ŒìŠ¤íŠ¸ ì™„ë£Œ: í‰ê·  {avg_cpu:.1f}%, ìµœëŒ€ {max_cpu:.1f}%")
            
        except Exception as e:
            self.log(f"âŒ CPU í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            self.test_results["cpu"] = {"error": str(e)}
    
    def test_concurrent_requests(self):
        """ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸"""
        self.log("ğŸ”„ ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        def make_request(url):
            try:
                start_time = time.time()
                response = requests.get(url, timeout=10)
                end_time = time.time()
                return {
                    "url": url,
                    "status_code": response.status_code,
                    "response_time": (end_time - start_time) * 1000,
                    "success": response.status_code == 200
                }
            except Exception as e:
                return {
                    "url": url,
                    "error": str(e),
                    "success": False
                }
        
        # ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
        urls = [
            f"{self.base_url}/",
            f"{self.base_url}/api/v1/posts",
            f"{self.base_url}/api/v1/keywords",
            f"{self.base_url}/api/v1/stats/dashboard"
        ] * 3  # ê° URLì„ 3ë²ˆì”©
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(make_request, url) for url in urls]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        end_time = time.time()
        total_time = end_time - start_time
        
        success_count = sum(1 for r in results if r["success"])
        avg_response_time = sum(r.get("response_time", 0) for r in results) / len(results) if results else 0
        
        self.test_results["concurrent_requests"] = {
            "total_requests": len(urls),
            "success_count": success_count,
            "success_rate": (success_count / len(urls)) * 100,
            "total_time": total_time,
            "requests_per_second": len(urls) / total_time,
            "average_response_time": avg_response_time,
            "details": results
        }
        
        self.log(f"ğŸ“Š ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(urls)} ì„±ê³µ, {len(urls)/total_time:.1f} req/s")
    
    def test_file_system(self):
        """íŒŒì¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        self.log("ğŸ“ íŒŒì¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        try:
            # ì£¼ìš” íŒŒì¼ ë° ë””ë ‰í† ë¦¬ í™•ì¸
            files_to_check = [
                "news_archive.db",
                "api_usage.json",
                "update_history.json",
                "crawling_stats.json",
                "site_crawler_configs.json",
                "synonyms.json"
            ]
            
            file_stats = {}
            total_size = 0
            
            for file_path in files_to_check:
                if os.path.exists(file_path):
                    size = os.path.getsize(file_path)
                    modified_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    file_stats[file_path] = {
                        "exists": True,
                        "size_bytes": size,
                        "size_kb": size / 1024,
                        "modified": modified_time.isoformat()
                    }
                    total_size += size
                else:
                    file_stats[file_path] = {"exists": False}
            
            # ë¡œê·¸ ë””ë ‰í† ë¦¬ í™•ì¸
            log_dir = "logs"
            log_files = []
            if os.path.exists(log_dir):
                for file in os.listdir(log_dir):
                    if file.endswith('.log'):
                        file_path = os.path.join(log_dir, file)
                        size = os.path.getsize(file_path)
                        log_files.append({
                            "name": file,
                            "size_bytes": size,
                            "size_kb": size / 1024
                        })
            
            self.test_results["file_system"] = {
                "total_files_checked": len(files_to_check),
                "existing_files": sum(1 for f in file_stats.values() if f.get("exists", False)),
                "total_size_bytes": total_size,
                "total_size_kb": total_size / 1024,
                "log_files_count": len(log_files),
                "file_stats": file_stats,
                "log_files": log_files
            }
            
            self.log(f"ğŸ“Š íŒŒì¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(files_to_check)}ê°œ íŒŒì¼, ì´ í¬ê¸°: {total_size/1024:.2f}KB")
            
        except Exception as e:
            self.log(f"âŒ íŒŒì¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            self.test_results["file_system"] = {"error": str(e)}
    
    def test_error_handling(self):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        self.log("âš ï¸ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        error_tests = [
            ("/api/v1/nonexistent", 404),
            ("/api/v1/posts?limit=invalid", 422),
            ("/api/v1/system/invalid", 404)
        ]
        
        results = []
        
        for url, expected_status in error_tests:
            try:
                response = requests.get(f"{self.base_url}{url}", timeout=5)
                results.append({
                    "url": url,
                    "expected_status": expected_status,
                    "actual_status": response.status_code,
                    "correct": response.status_code == expected_status
                })
            except Exception as e:
                results.append({
                    "url": url,
                    "expected_status": expected_status,
                    "error": str(e),
                    "correct": False
                })
        
        correct_count = sum(1 for r in results if r["correct"])
        
        self.test_results["error_handling"] = {
            "total_tests": len(error_tests),
            "correct_count": correct_count,
            "success_rate": (correct_count / len(error_tests)) * 100,
            "details": results
        }
        
        self.log(f"ğŸ“Š ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {correct_count}/{len(error_tests)} ì„±ê³µ")
    
    def generate_optimization_report(self):
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        self.log("ğŸ“‹ ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±")
        
        total_time = time.time() - self.start_time
        
        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        api_score = self.test_results.get("api_endpoints", {}).get("success_rate", 0)
        db_score = 100 if self.test_results.get("database", {}).get("table_count", 0) > 0 else 0
        memory_score = 100 - self.test_results.get("memory", {}).get("memory_percent", 100)
        cpu_score = 100 - self.test_results.get("cpu", {}).get("average_cpu_percent", 100)
        concurrent_score = self.test_results.get("concurrent_requests", {}).get("success_rate", 0)
        error_score = self.test_results.get("error_handling", {}).get("success_rate", 0)
        
        overall_score = (api_score + db_score + memory_score + cpu_score + concurrent_score + error_score) / 6
        
        report = {
            "test_summary": {
                "total_test_time": total_time,
                "overall_score": overall_score,
                "test_timestamp": datetime.now().isoformat()
            },
            "performance_metrics": {
                "api_success_rate": api_score,
                "database_health": db_score,
                "memory_efficiency": memory_score,
                "cpu_efficiency": cpu_score,
                "concurrent_performance": concurrent_score,
                "error_handling": error_score
            },
            "detailed_results": self.test_results,
            "recommendations": self.generate_recommendations()
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        with open("system_optimization_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.log(f"ğŸ“Š ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: ì „ì²´ ì ìˆ˜ {overall_score:.1f}/100")
        
        return report
    
    def generate_recommendations(self):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # API ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­
        api_results = self.test_results.get("api_endpoints", {})
        if api_results.get("average_response_time", 0) > 500:
            recommendations.append("API ì‘ë‹µì‹œê°„ì´ 500msë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ìºì‹± ì „ëµì„ ê²€í† í•˜ì„¸ìš”.")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¶Œì¥ì‚¬í•­
        memory_results = self.test_results.get("memory", {})
        if memory_results.get("memory_percent", 0) > 80:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ 80%ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # CPU ì‚¬ìš©ëŸ‰ ê¶Œì¥ì‚¬í•­
        cpu_results = self.test_results.get("cpu", {})
        if cpu_results.get("average_cpu_percent", 0) > 70:
            recommendations.append("CPU ì‚¬ìš©ë¥ ì´ 70%ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. CPU ì§‘ì•½ì  ì‘ì—…ì„ ìµœì í™”í•˜ì„¸ìš”.")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê¶Œì¥ì‚¬í•­
        db_results = self.test_results.get("database", {})
        if db_results.get("db_size_kb", 0) > 10240:  # 10MB
            recommendations.append("ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ì •ë¦¬ ì‘ì—…ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # ë™ì‹œ ìš”ì²­ ê¶Œì¥ì‚¬í•­
        concurrent_results = self.test_results.get("concurrent_requests", {})
        if concurrent_results.get("success_rate", 0) < 95:
            recommendations.append("ë™ì‹œ ìš”ì²­ ì„±ê³µë¥ ì´ 95% ë¯¸ë§Œì…ë‹ˆë‹¤. ì„œë²„ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœì…ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.log("ğŸš€ ì „ì²´ ì‹œìŠ¤í…œ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        try:
            # 1. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
            self.test_api_endpoints()
            
            # 2. ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            self.test_database_performance()
            
            # 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
            self.test_memory_usage()
            
            # 4. CPU ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
            self.test_cpu_usage()
            
            # 5. ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
            self.test_concurrent_requests()
            
            # 6. íŒŒì¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
            self.test_file_system()
            
            # 7. ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            self.test_error_handling()
            
            # 8. ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±
            report = self.generate_optimization_report()
            
            # 9. ê²°ê³¼ ì¶œë ¥
            self.print_summary(report)
            
        except Exception as e:
            self.log(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def print_summary(self, report):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ¯ ì „ì²´ ì‹œìŠ¤í…œ ìµœì í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 60)
        
        summary = report["test_summary"]
        metrics = report["performance_metrics"]
        
        print(f"ğŸ“Š ì „ì²´ ì ìˆ˜: {summary['overall_score']:.1f}/100")
        print(f"â±ï¸  í…ŒìŠ¤íŠ¸ ì‹œê°„: {summary['total_test_time']:.2f}ì´ˆ")
        print(f"ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {summary['test_timestamp']}")
        
        print("\nğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   API ì„±ê³µë¥ : {metrics['api_success_rate']:.1f}%")
        print(f"   ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ: {metrics['database_health']:.1f}%")
        print(f"   ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {metrics['memory_efficiency']:.1f}%")
        print(f"   CPU íš¨ìœ¨ì„±: {metrics['cpu_efficiency']:.1f}%")
        print(f"   ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥: {metrics['concurrent_performance']:.1f}%")
        print(f"   ì—ëŸ¬ ì²˜ë¦¬: {metrics['error_handling']:.1f}%")
        
        print("\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(report["recommendations"], 1):
            print(f"   {i}. {rec}")
        
        print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸: system_optimization_report.json")
        print("=" * 60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = SystemOptimizationTest()
    tester.run_all_tests()

if __name__ == "__main__":
    main() 