#!/usr/bin/env python3
"""
ì„±ëŠ¥ ìµœì í™” ë° ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
í¬ë¡¤ë§ â†’ ë²ˆì—­ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ ì½˜í…ì¸  ìƒì„± íŒŒì´í”„ë¼ì¸ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
import os
import json
import requests
import time
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import statistics

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.config import settings

class PerformanceOptimizationTest:
    """ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.test_results = {
            "timestamp": datetime.now().isoformat(),
            "tests": [],
            "performance_stats": {},
            "error_stats": {}
        }
    
    def test_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í…ŒìŠ¤íŠ¸"""
        print("ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘...")
        try:
            response = requests.get(f"{self.base_url}/api/v1/system-status", timeout=30)
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… ì‹œìŠ¤í…œ ìƒíƒœ: {data.get('overall_status', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                print(f"   - CPU ì‚¬ìš©ë¥ : {data.get('system', {}).get('cpu_usage', 'N/A')}")
                print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {data.get('system', {}).get('memory_usage', 'N/A')}")
                print(f"   - OpenAI API: {'âœ…' if data.get('apis', {}).get('openai') else 'âŒ'}")
                print(f"   - Gemini API: {'âœ…' if data.get('apis', {}).get('gemini') else 'âŒ'}")
                
                # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
                if 'performance' in data and 'stats' in data['performance']:
                    print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
                    for operation, stats in data['performance']['stats'].items():
                        if isinstance(stats, dict) and 'avg_time' in stats:
                            print(f"   - {operation}: í‰ê·  {stats['avg_time']:.2f}ì´ˆ")
                
                # ì—ëŸ¬ í†µê³„ ì¶œë ¥
                if 'errors' in data:
                    print("\nâš ï¸ ì—ëŸ¬ í†µê³„:")
                    error_stats = data['errors']
                    if isinstance(error_stats, dict):
                        total_errors = error_stats.get('total_errors', 0)
                        print(f"   - ì´ ì—ëŸ¬ ìˆ˜: {total_errors}")
                        if 'error_counts' in error_stats:
                            for error_type, count in error_stats['error_counts'].items():
                                print(f"   - {error_type}: {count}íšŒ")
                
                return True
            else:
                print(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def test_single_pipeline_performance(self, test_name: str, test_data: dict, expected_duration: float = 30.0):
        """ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nâš¡ {test_name} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        try:
            start_time = time.time()
            response = requests.post(
                f"{self.base_url}/api/v1/generate-post-gemini-2-flash",
                json=test_data,
                timeout=expected_duration + 10
            )
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                content_length = len(data.get('data', {}).get('content', ''))
                
                # ì„±ëŠ¥ í‰ê°€
                performance_score = "ì¢‹ìŒ" if duration < expected_duration else "ë³´í†µ"
                if duration > expected_duration * 1.5:
                    performance_score = "ëŠë¦¼"
                
                print(f"âœ… {test_name} ì„±ê³µ ({duration:.2f}ì´ˆ)")
                print(f"   - ì½˜í…ì¸  ê¸¸ì´: {content_length}ì")
                print(f"   - ì„±ëŠ¥ í‰ê°€: {performance_score}")
                
                result = {
                    "test": test_name,
                    "status": "success",
                    "duration": round(duration, 2),
                    "content_length": content_length,
                    "performance_score": performance_score
                }
            else:
                print(f"âŒ {test_name} ì‹¤íŒ¨: {response.status_code}")
                result = {
                    "test": test_name,
                    "status": "failed",
                    "error": f"HTTP {response.status_code}",
                    "duration": round(duration, 2)
                }
            
            self.test_results["tests"].append(result)
            return result["status"] == "success"
            
        except Exception as e:
            print(f"âŒ {test_name} ì˜¤ë¥˜: {e}")
            result = {
                "test": test_name,
                "status": "error",
                "error": str(e),
                "duration": 0
            }
            self.test_results["tests"].append(result)
            return False
    
    def test_concurrent_pipelines(self, num_concurrent: int = 3):
        """ë™ì‹œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ”„ ë™ì‹œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ({num_concurrent}ê°œ)...")
        
        test_data = {
            "text": "Artificial Intelligence is transforming the world.",
            "ai_mode": "gemini_2_0_flash",
            "content_length": "2000",
            "rules": ["AI_SEO"]
        }
        
        def run_single_test():
            try:
                start_time = time.time()
                response = requests.post(
                    f"{self.base_url}/api/v1/generate-post-gemini-2-flash",
                    json=test_data,
                    timeout=60
                )
                duration = time.time() - start_time
                
                if response.status_code == 200:
                    return {"status": "success", "duration": duration}
                else:
                    return {"status": "failed", "duration": duration, "error": response.status_code}
            except Exception as e:
                return {"status": "error", "duration": 0, "error": str(e)}
        
        # ë™ì‹œ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=num_concurrent) as executor:
            futures = [executor.submit(run_single_test) for _ in range(num_concurrent)]
            results = [future.result() for future in futures]
        
        # ê²°ê³¼ ë¶„ì„
        successful_results = [r for r in results if r["status"] == "success"]
        durations = [r["duration"] for r in successful_results]
        
        if durations:
            avg_duration = statistics.mean(durations)
            min_duration = min(durations)
            max_duration = max(durations)
            
            print(f"âœ… ë™ì‹œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            print(f"   - ì„±ê³µë¥ : {len(successful_results)}/{num_concurrent} ({len(successful_results)/num_concurrent*100:.1f}%)")
            print(f"   - í‰ê·  ì‹œê°„: {avg_duration:.2f}ì´ˆ")
            print(f"   - ìµœì†Œ ì‹œê°„: {min_duration:.2f}ì´ˆ")
            print(f"   - ìµœëŒ€ ì‹œê°„: {max_duration:.2f}ì´ˆ")
            
            result = {
                "test": "concurrent_pipelines",
                "status": "success",
                "concurrent_count": num_concurrent,
                "success_rate": len(successful_results) / num_concurrent,
                "avg_duration": round(avg_duration, 2),
                "min_duration": round(min_duration, 2),
                "max_duration": round(max_duration, 2)
            }
        else:
            print(f"âŒ ë™ì‹œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            result = {
                "test": "concurrent_pipelines",
                "status": "failed",
                "concurrent_count": num_concurrent,
                "success_rate": 0
            }
        
        self.test_results["tests"].append(result)
        return result["status"] == "success"
    
    def test_error_handling(self):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")
        
        test_cases = [
            {
                "name": "ë¹ˆ í…ìŠ¤íŠ¸",
                "data": {"text": "", "ai_mode": "gemini_2_0_flash"},
                "expected": "400"
            },
            {
                "name": "ìœ íš¨í•˜ì§€ ì•Šì€ URL",
                "data": {"url": "invalid-url", "ai_mode": "gemini_2_0_flash"},
                "expected": "400"
            },
            {
                "name": "ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸",
                "data": {"text": "A" * 100000, "ai_mode": "gemini_2_0_flash"},
                "expected": "400"
            }
        ]
        
        error_handling_results = []
        
        for test_case in test_cases:
            try:
                response = requests.post(
                    f"{self.base_url}/api/v1/generate-post-gemini-2-flash",
                    json=test_case["data"],
                    timeout=30
                )
                
                if response.status_code == int(test_case["expected"]):
                    print(f"âœ… {test_case['name']}: ì˜¬ë°”ë¥¸ ì—ëŸ¬ ì²˜ë¦¬")
                    error_handling_results.append({"test": test_case["name"], "status": "success"})
                else:
                    print(f"âŒ {test_case['name']}: ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ ({response.status_code})")
                    error_handling_results.append({"test": test_case["name"], "status": "failed", "actual": response.status_code})
                    
            except Exception as e:
                print(f"âŒ {test_case['name']}: ì˜ˆì™¸ ë°œìƒ - {e}")
                error_handling_results.append({"test": test_case["name"], "status": "error", "error": str(e)})
        
        # ì „ì²´ ì—ëŸ¬ ì²˜ë¦¬ í‰ê°€
        success_count = sum(1 for r in error_handling_results if r["status"] == "success")
        success_rate = success_count / len(test_cases)
        
        result = {
            "test": "error_handling",
            "status": "success" if success_rate >= 0.8 else "partial",
            "success_rate": success_rate,
            "details": error_handling_results
        }
        
        self.test_results["tests"].append(result)
        return success_rate >= 0.8
    
    def test_cache_performance(self):
        """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ’¾ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        test_data = {
            "text": "This is a test for cache performance.",
            "ai_mode": "gemini_2_0_flash",
            "content_length": "1000",
            "rules": ["AI_SEO"]
        }
        
        # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
        start_time = time.time()
        response1 = requests.post(
            f"{self.base_url}/api/v1/generate-post-gemini-2-flash",
            json=test_data,
            timeout=60
        )
        first_duration = time.time() - start_time
        
        # ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ íˆíŠ¸)
        start_time = time.time()
        response2 = requests.post(
            f"{self.base_url}/api/v1/generate-post-gemini-2-flash",
            json=test_data,
            timeout=60
        )
        second_duration = time.time() - start_time
        
        if response1.status_code == 200 and response2.status_code == 200:
            speedup = first_duration / second_duration if second_duration > 0 else 0
            
            print(f"âœ… ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            print(f"   - ì²« ë²ˆì§¸ ìš”ì²­: {first_duration:.2f}ì´ˆ")
            print(f"   - ë‘ ë²ˆì§¸ ìš”ì²­: {second_duration:.2f}ì´ˆ")
            print(f"   - ì†ë„ í–¥ìƒ: {speedup:.1f}ë°°")
            
            result = {
                "test": "cache_performance",
                "status": "success",
                "first_request": round(first_duration, 2),
                "second_request": round(second_duration, 2),
                "speedup": round(speedup, 1)
            }
        else:
            print(f"âŒ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            result = {
                "test": "cache_performance",
                "status": "failed",
                "first_status": response1.status_code,
                "second_status": response2.status_code
            }
        
        self.test_results["tests"].append(result)
        return result["status"] == "success"
    
    def save_results(self, filename: str = None):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"performance_optimization_test_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*60)
        
        total_tests = len(self.test_results["tests"])
        successful_tests = sum(1 for test in self.test_results["tests"] if test.get("status") == "success")
        failed_tests = total_tests - successful_tests
        
        print(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {total_tests}")
        print(f"ì„±ê³µ: {successful_tests}")
        print(f"ì‹¤íŒ¨: {failed_tests}")
        print(f"ì„±ê³µë¥ : {(successful_tests/total_tests*100):.1f}%" if total_tests > 0 else "0%")
        
        if self.test_results["tests"]:
            print("\nìƒì„¸ ê²°ê³¼:")
            for i, test in enumerate(self.test_results["tests"], 1):
                print(f"{i}. {test.get('test', 'unknown')}: {test.get('status', 'unknown')}")
                if test.get('duration'):
                    print(f"   ì†Œìš”ì‹œê°„: {test['duration']}ì´ˆ")
                if test.get('performance_score'):
                    print(f"   ì„±ëŠ¥ í‰ê°€: {test['performance_score']}")
                if test.get('success_rate'):
                    print(f"   ì„±ê³µë¥ : {test['success_rate']*100:.1f}%")
                if test.get('error'):
                    print(f"   ì˜¤ë¥˜: {test['error']}")
        
        # ì„±ëŠ¥ í†µê³„
        duration_tests = [test for test in self.test_results["tests"] if test.get("duration")]
        if duration_tests:
            durations = [test["duration"] for test in duration_tests]
            print(f"\nì„±ëŠ¥ í†µê³„:")
            print(f"   í‰ê·  ì‹œê°„: {statistics.mean(durations):.2f}ì´ˆ")
            print(f"   ì¤‘ê°„ê°’: {statistics.median(durations):.2f}ì´ˆ")
            print(f"   ìµœì†Œ ì‹œê°„: {min(durations):.2f}ì´ˆ")
            print(f"   ìµœëŒ€ ì‹œê°„: {max(durations):.2f}ì´ˆ")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("í¬ë¡¤ë§ â†’ ë²ˆì—­ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ ì½˜í…ì¸  ìƒì„± íŒŒì´í”„ë¼ì¸")
    
    # API í‚¤ í™•ì¸ - Gemini API ìˆ¨ê¹€ ì²˜ë¦¬ë¨
    # if not settings.get_gemini_api_key():
    #     print("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    #     print("í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    #     return
    
    # print("âœ… Gemini API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("â„¹ï¸ Gemini API ê¸°ëŠ¥ì´ ìˆ¨ê¹€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # í…ŒìŠ¤íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    tester = PerformanceOptimizationTest()
    
    # 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    if not tester.test_system_status():
        print("âŒ ì‹œìŠ¤í…œì´ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return
    
    # 2. ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    test_cases = [
        {
            "name": "ì§§ì€ í…ìŠ¤íŠ¸",
            "data": {
                "text": "AI is transforming the world.",
                "ai_mode": "gemini_2_0_flash",
                "content_length": "1000",
                "rules": ["AI_SEO"]
            },
            "expected_duration": 20.0
        },
        {
            "name": "ì¤‘ê°„ í…ìŠ¤íŠ¸",
            "data": {
                "text": "Artificial Intelligence is revolutionizing various industries including healthcare, finance, and education. The technology continues to evolve rapidly.",
                "ai_mode": "gemini_2_0_flash",
                "content_length": "3000",
                "rules": ["AI_SEO", "AI_SEARCH"]
            },
            "expected_duration": 30.0
        },
        {
            "name": "ê¸´ í…ìŠ¤íŠ¸",
            "data": {
                "text": "Artificial Intelligence (AI) is transforming the way we live and work. From virtual assistants to autonomous vehicles, AI technologies are becoming increasingly integrated into our daily lives. Machine learning algorithms can now process vast amounts of data to identify patterns and make predictions with remarkable accuracy. The impact of AI on various industries is profound. In healthcare, AI is helping doctors diagnose diseases more accurately and develop personalized treatment plans. In finance, AI algorithms are detecting fraudulent transactions and optimizing investment strategies. In education, AI-powered platforms are providing personalized learning experiences for students.",
                "ai_mode": "gemini_2_0_flash",
                "content_length": "5000",
                "rules": ["AI_SEO", "AI_SEARCH", "POLICY"]
            },
            "expected_duration": 40.0
        }
    ]
    
    for test_case in test_cases:
        tester.test_single_pipeline_performance(
            test_case["name"], 
            test_case["data"], 
            test_case["expected_duration"]
        )
    
    # 3. ë™ì‹œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    tester.test_concurrent_pipelines(num_concurrent=3)
    
    # 4. ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    tester.test_error_handling()
    
    # 5. ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    tester.test_cache_performance()
    
    # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
    tester.save_results()
    tester.print_summary()
    
    print("\nâœ… ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main() 