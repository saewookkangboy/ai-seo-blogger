#!/usr/bin/env python3
"""
ì„±ëŠ¥ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ìµœì í™” í¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""
import requests
import time
import threading
import concurrent.futures
import statistics
from datetime import datetime
import json

class PerformanceStressTest:
    def __init__(self):
        self.base_url = "http://localhost:8000"
        self.results = {}
        
    def log(self, message):
        """ë¡œê·¸ ì¶œë ¥"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}")
    
    def test_single_endpoint_stress(self, endpoint, num_requests=100, max_workers=10):
        """ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        self.log(f"ğŸ”¥ {endpoint} ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({num_requests} ìš”ì²­, {max_workers} ë™ì‹œ)")
        
        def make_request():
            try:
                start_time = time.time()
                response = requests.get(f"{self.base_url}{endpoint}", timeout=30)
                end_time = time.time()
                return {
                    "status_code": response.status_code,
                    "response_time": (end_time - start_time) * 1000,
                    "success": response.status_code == 200,
                    "timestamp": datetime.now().isoformat()
                }
            except Exception as e:
                return {
                    "status_code": 0,
                    "response_time": 0,
                    "success": False,
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_list = [executor.submit(make_request) for _ in range(num_requests)]
            results = [future.result() for future in concurrent.futures.as_completed(future_list)]
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]
        
        response_times = [r["response_time"] for r in successful_requests]
        
        stats = {
            "total_requests": num_requests,
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "success_rate": (len(successful_requests) / num_requests) * 100,
            "total_time": total_time,
            "requests_per_second": num_requests / total_time,
            "avg_response_time": statistics.mean(response_times) if response_times else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0,
            "median_response_time": statistics.median(response_times) if response_times else 0,
            "p95_response_time": statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else 0,
            "p99_response_time": statistics.quantiles(response_times, n=100)[98] if len(response_times) >= 100 else 0
        }
        
        self.log(f"ğŸ“Š {endpoint} ê²°ê³¼: {stats['success_rate']:.1f}% ì„±ê³µ, {stats['requests_per_second']:.1f} req/s, í‰ê·  {stats['avg_response_time']:.2f}ms")
        
        return {
            "endpoint": endpoint,
            "stats": stats,
            "results": results
        }
    
    def test_mixed_endpoints_stress(self, duration=60):
        """í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        self.log(f"ğŸ”¥ í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({duration}ì´ˆ)")
        
        endpoints = [
            "/",
            "/api/v1/posts",
            "/api/v1/keywords",
            "/api/v1/stats/dashboard",
            "/api/v1/system/uptime",
            "/api/v1/feature-updates/history"
        ]
        
        results = []
        start_time = time.time()
        
        def worker():
            while time.time() - start_time < duration:
                for endpoint in endpoints:
                    try:
                        request_start = time.time()
                        response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                        request_end = time.time()
                        
                        results.append({
                            "endpoint": endpoint,
                            "status_code": response.status_code,
                            "response_time": (request_end - request_start) * 1000,
                            "success": response.status_code == 200,
                            "timestamp": datetime.now().isoformat()
                        })
                        
                        # ì§§ì€ ëŒ€ê¸° ì‹œê°„
                        time.sleep(0.1)
                        
                    except Exception as e:
                        results.append({
                            "endpoint": endpoint,
                            "status_code": 0,
                            "response_time": 0,
                            "success": False,
                            "error": str(e),
                            "timestamp": datetime.now().isoformat()
                        })
        
        # ì—¬ëŸ¬ ìŠ¤ë ˆë“œë¡œ ë™ì‹œ ì‹¤í–‰
        threads = []
        for _ in range(5):  # 5ê°œ ìŠ¤ë ˆë“œ
            thread = threading.Thread(target=worker)
            thread.start()
            threads.append(thread)
        
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
        for thread in threads:
            thread.join()
        
        # ê²°ê³¼ ë¶„ì„
        total_requests = len(results)
        successful_requests = [r for r in results if r["success"]]
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„
        endpoint_stats = {}
        for endpoint in endpoints:
            endpoint_results = [r for r in results if r["endpoint"] == endpoint]
            endpoint_successful = [r for r in endpoint_results if r["success"]]
            
            if endpoint_successful:
                response_times = [r["response_time"] for r in endpoint_successful]
                endpoint_stats[endpoint] = {
                    "total_requests": len(endpoint_results),
                    "successful_requests": len(endpoint_successful),
                    "success_rate": (len(endpoint_successful) / len(endpoint_results)) * 100,
                    "avg_response_time": statistics.mean(response_times),
                    "min_response_time": min(response_times),
                    "max_response_time": max(response_times),
                    "median_response_time": statistics.median(response_times)
                }
        
        overall_stats = {
            "duration": duration,
            "total_requests": total_requests,
            "successful_requests": len(successful_requests),
            "success_rate": (len(successful_requests) / total_requests) * 100,
            "requests_per_second": total_requests / duration,
            "endpoint_stats": endpoint_stats
        }
        
        self.log(f"ğŸ“Š í˜¼í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼: {overall_stats['success_rate']:.1f}% ì„±ê³µ, {overall_stats['requests_per_second']:.1f} req/s")
        
        return {
            "test_type": "mixed_endpoints",
            "stats": overall_stats,
            "results": results
        }
    
    def test_memory_leak_detection(self, duration=120):
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        self.log(f"ğŸ§  ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({duration}ì´ˆ)")
        
        import psutil
        process = psutil.Process()
        
        memory_samples = []
        start_time = time.time()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        while time.time() - start_time < duration:
            memory_info = process.memory_info()
            memory_samples.append({
                "timestamp": datetime.now().isoformat(),
                "rss_mb": memory_info.rss / (1024 * 1024),
                "vms_mb": memory_info.vms / (1024 * 1024),
                "elapsed_time": time.time() - start_time
            })
            
            # API ìš”ì²­ ìˆ˜í–‰
            try:
                requests.get(f"{self.base_url}/api/v1/posts", timeout=5)
                requests.get(f"{self.base_url}/api/v1/keywords", timeout=5)
                requests.get(f"{self.base_url}/api/v1/stats/dashboard", timeout=5)
            except:
                pass
            
            time.sleep(5)  # 5ì´ˆë§ˆë‹¤ ìƒ˜í”Œë§
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
        rss_values = [sample["rss_mb"] for sample in memory_samples]
        vms_values = [sample["vms_mb"] for sample in memory_samples]
        
        memory_analysis = {
            "duration": duration,
            "samples_count": len(memory_samples),
            "rss_start_mb": rss_values[0] if rss_values else 0,
            "rss_end_mb": rss_values[-1] if rss_values else 0,
            "rss_increase_mb": rss_values[-1] - rss_values[0] if len(rss_values) > 1 else 0,
            "rss_increase_percent": ((rss_values[-1] - rss_values[0]) / rss_values[0] * 100) if len(rss_values) > 1 and rss_values[0] > 0 else 0,
            "vms_start_mb": vms_values[0] if vms_values else 0,
            "vms_end_mb": vms_values[-1] if vms_values else 0,
            "vms_increase_mb": vms_values[-1] - vms_values[0] if len(vms_values) > 1 else 0,
            "max_rss_mb": max(rss_values) if rss_values else 0,
            "min_rss_mb": min(rss_values) if rss_values else 0,
            "avg_rss_mb": statistics.mean(rss_values) if rss_values else 0
        }
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒë‹¨
        memory_leak_detected = False
        if memory_analysis["rss_increase_percent"] > 20:  # 20% ì´ìƒ ì¦ê°€ ì‹œ ëˆ„ìˆ˜ ì˜ì‹¬
            memory_leak_detected = True
        
        self.log(f"ğŸ“Š ë©”ëª¨ë¦¬ ë¶„ì„: RSS {memory_analysis['rss_increase_mb']:.2f}MB ì¦ê°€ ({memory_analysis['rss_increase_percent']:.1f}%)")
        
        if memory_leak_detected:
            self.log("âš ï¸ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            self.log("âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì•ˆì •ì ì…ë‹ˆë‹¤.")
        
        return {
            "test_type": "memory_leak_detection",
            "memory_analysis": memory_analysis,
            "memory_leak_detected": memory_leak_detected,
            "samples": memory_samples
        }
    
    def test_database_performance_under_load(self, num_requests=500):
        """ë¶€í•˜ í•˜ì—ì„œì˜ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.log(f"ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({num_requests} ìš”ì²­)")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì§‘ì•½ì  ì—”ë“œí¬ì¸íŠ¸ë“¤
        db_endpoints = [
            "/api/v1/posts",
            "/api/v1/keywords",
            "/api/v1/stats/dashboard",
            "/api/v1/feature-updates/history"
        ]
        
        results = []
        
        def make_db_request():
            endpoint = db_endpoints[hash(str(time.time())) % len(db_endpoints)]
            try:
                start_time = time.time()
                response = requests.get(f"{self.base_url}{endpoint}", timeout=30)
                end_time = time.time()
                return {
                    "endpoint": endpoint,
                    "status_code": response.status_code,
                    "response_time": (end_time - start_time) * 1000,
                    "success": response.status_code == 200,
                    "timestamp": datetime.now().isoformat()
                }
            except Exception as e:
                return {
                    "endpoint": endpoint,
                    "status_code": 0,
                    "response_time": 0,
                    "success": False,
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
            future_list = [executor.submit(make_db_request) for _ in range(num_requests)]
            results = [future.result() for future in concurrent.futures.as_completed(future_list)]
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful_requests = [r for r in results if r["success"]]
        response_times = [r["response_time"] for r in successful_requests]
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ ë¶„ì„
        endpoint_analysis = {}
        for endpoint in db_endpoints:
            endpoint_results = [r for r in results if r["endpoint"] == endpoint]
            endpoint_successful = [r for r in endpoint_results if r["success"]]
            
            if endpoint_successful:
                endpoint_response_times = [r["response_time"] for r in endpoint_successful]
                endpoint_analysis[endpoint] = {
                    "total_requests": len(endpoint_results),
                    "successful_requests": len(endpoint_successful),
                    "success_rate": (len(endpoint_successful) / len(endpoint_results)) * 100,
                    "avg_response_time": statistics.mean(endpoint_response_times),
                    "min_response_time": min(endpoint_response_times),
                    "max_response_time": max(endpoint_response_times),
                    "median_response_time": statistics.median(endpoint_response_times),
                    "p95_response_time": statistics.quantiles(endpoint_response_times, n=20)[18] if len(endpoint_response_times) >= 20 else 0
                }
        
        db_performance = {
            "total_requests": num_requests,
            "successful_requests": len(successful_requests),
            "success_rate": (len(successful_requests) / num_requests) * 100,
            "total_time": total_time,
            "requests_per_second": num_requests / total_time,
            "avg_response_time": statistics.mean(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "median_response_time": statistics.median(response_times) if response_times else 0,
            "p95_response_time": statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else 0,
            "endpoint_analysis": endpoint_analysis
        }
        
        self.log(f"ğŸ“Š DB ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {db_performance['success_rate']:.1f}% ì„±ê³µ, {db_performance['requests_per_second']:.1f} req/s")
        
        return {
            "test_type": "database_performance_under_load",
            "performance": db_performance,
            "results": results
        }
    
    def run_comprehensive_stress_test(self):
        """ì¢…í•© ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.log("ğŸš€ ì¢…í•© ì„±ëŠ¥ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        try:
            # 1. ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
            self.log("1ë‹¨ê³„: ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸")
            self.results["single_endpoint"] = self.test_single_endpoint_stress("/api/v1/posts", 200, 20)
            
            # 2. í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
            self.log("2ë‹¨ê³„: í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸")
            self.results["mixed_endpoints"] = self.test_mixed_endpoints_stress(30)  # 30ì´ˆ
            
            # 3. ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ í…ŒìŠ¤íŠ¸
            self.log("3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ í…ŒìŠ¤íŠ¸")
            self.results["database_load"] = self.test_database_performance_under_load(300)
            
            # 4. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸
            self.log("4ë‹¨ê³„: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸")
            self.results["memory_leak"] = self.test_memory_leak_detection(60)  # 60ì´ˆ
            
            # 5. ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
            self.generate_stress_test_report()
            
        except Exception as e:
            self.log(f"âŒ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def generate_stress_test_report(self):
        """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        self.log("ğŸ“‹ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±")
        
        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        single_score = min(100, self.results["single_endpoint"]["stats"]["success_rate"])
        mixed_score = min(100, self.results["mixed_endpoints"]["stats"]["success_rate"])
        db_score = min(100, self.results["database_load"]["performance"]["success_rate"])
        memory_score = 100 if not self.results["memory_leak"]["memory_leak_detected"] else 50
        
        overall_score = (single_score + mixed_score + db_score + memory_score) / 4
        
        report = {
            "test_summary": {
                "overall_score": overall_score,
                "test_timestamp": datetime.now().isoformat(),
                "performance_metrics": {
                    "single_endpoint_performance": single_score,
                    "mixed_endpoints_performance": mixed_score,
                    "database_performance": db_score,
                    "memory_stability": memory_score
                }
            },
            "detailed_results": self.results,
            "recommendations": self.generate_stress_test_recommendations()
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        with open("performance_stress_test_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.print_stress_test_summary(report)
        
        return report
    
    def generate_stress_test_recommendations(self):
        """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ì„±ëŠ¥ ë¶„ì„
        single_stats = self.results["single_endpoint"]["stats"]
        if single_stats["success_rate"] < 95:
            recommendations.append("ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ì„±ê³µë¥ ì´ 95% ë¯¸ë§Œì…ë‹ˆë‹¤. ì„œë²„ ë¦¬ì†ŒìŠ¤ë‚˜ ì—°ê²° í’€ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        if single_stats["p95_response_time"] > 1000:
            recommendations.append("95% ì‘ë‹µì‹œê°„ì´ 1ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ìºì‹±ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ì„±ëŠ¥ ë¶„ì„
        mixed_stats = self.results["mixed_endpoints"]["stats"]
        if mixed_stats["success_rate"] < 90:
            recommendations.append("í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ì„±ê³µë¥ ì´ 90% ë¯¸ë§Œì…ë‹ˆë‹¤. ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ì„ ê°œì„ í•˜ì„¸ìš”.")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë¶„ì„
        db_perf = self.results["database_load"]["performance"]
        if db_perf["success_rate"] < 95:
            recommendations.append("ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ ì´ 95% ë¯¸ë§Œì…ë‹ˆë‹¤. DB ì—°ê²° í’€ê³¼ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        # ë©”ëª¨ë¦¬ ë¶„ì„
        memory_analysis = self.results["memory_leak"]["memory_analysis"]
        if memory_analysis["rss_increase_percent"] > 20:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 20% ì´ìƒ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ í™•ì¸í•˜ê³  ìµœì í™”í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ì‹œìŠ¤í…œì´ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ í†µê³¼í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations
    
    def print_stress_test_summary(self, report):
        """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ”¥ ì„±ëŠ¥ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 60)
        
        summary = report["test_summary"]
        metrics = summary["performance_metrics"]
        
        print(f"ğŸ“Š ì „ì²´ ì ìˆ˜: {summary['overall_score']:.1f}/100")
        print(f"ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {summary['test_timestamp']}")
        
        print("\nğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   ë‹¨ì¼ ì—”ë“œí¬ì¸íŠ¸ ì„±ëŠ¥: {metrics['single_endpoint_performance']:.1f}%")
        print(f"   í˜¼í•© ì—”ë“œí¬ì¸íŠ¸ ì„±ëŠ¥: {metrics['mixed_endpoints_performance']:.1f}%")
        print(f"   ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥: {metrics['database_performance']:.1f}%")
        print(f"   ë©”ëª¨ë¦¬ ì•ˆì •ì„±: {metrics['memory_stability']:.1f}%")
        
        print("\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(report["recommendations"], 1):
            print(f"   {i}. {rec}")
        
        print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸: performance_stress_test_report.json")
        print("=" * 60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = PerformanceStressTest()
    tester.run_comprehensive_stress_test()

if __name__ == "__main__":
    main() 